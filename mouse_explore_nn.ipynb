{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:05:46.328768500Z",
     "start_time": "2024-06-26T21:05:46.322783800Z"
    }
   },
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_input():\n",
    "    X = []\n",
    "    y = []\n",
    "    df = pd.read_csv(\"classification_data/explore_img/explore_data.csv\")\n",
    "    shuffled_df = df.sample(len(df))\n",
    "\n",
    "    print(shuffled_df.head)\n",
    "    s = 0\n",
    "    for entry in shuffled_df.values:\n",
    "        s += 1\n",
    "        # print(s)\n",
    "        entry_img = cv2.imread(f\"classification_data/explore_img/{entry[0]}\")\n",
    "\n",
    "        prepared_y = np.delete(entry,0) * 3\n",
    "        print(prepared_y)\n",
    "        if prepared_y[0] >= 960:\n",
    "            prepared_y[0] = prepared_y[0] - 960\n",
    "        else:\n",
    "            prepared_y[0] = -prepared_y[0]\n",
    "            \n",
    "        if prepared_y[1] >= 540:\n",
    "            prepared_y[1] = prepared_y[1] - 540\n",
    "        else:\n",
    "            prepared_y[1] = -prepared_y[1]\n",
    "        X.append(entry_img)\n",
    "        print(prepared_y, 'normalized')\n",
    "        y.append(prepared_y)\n",
    "        \n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).astype(np.float32)\n",
    "    return X, y\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:20:50.465521400Z",
     "start_time": "2024-06-26T21:20:50.444400Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compile_model():\n",
    "    image_width, image_height, channels = 640, 360, 3  # Assuming RGB images\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(image_height, image_width, channels)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "\n",
    "    return model\n",
    "\n",
    "model = compile_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:05:56.685856100Z",
     "start_time": "2024-06-26T21:05:56.335706100Z"
    }
   },
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:05:59.806286200Z",
     "start_time": "2024-06-26T21:05:59.789629Z"
    }
   },
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             filename    x    y\n",
      "77    explore_77.jpg  100  268\n",
      "21    explore_21.jpg   40   65\n",
      "10    explore_10.jpg  274   26\n",
      "15    explore_15.jpg  182   38\n",
      "153  explore_153.jpg  223  272\n",
      "..               ...  ...  ...\n",
      "5      explore_5.jpg  212  286\n",
      "61    explore_61.jpg  248  124\n",
      "144  explore_144.jpg  455   60\n",
      "87    explore_87.jpg  360   28\n",
      "72    explore_72.jpg  354  338\n",
      "\n",
      "[160 rows x 3 columns]>\n",
      "[300 804]\n",
      "[-300 264] normalized\n",
      "[120 195]\n",
      "[-120 -195] normalized\n",
      "[822 78]\n",
      "[-822 -78] normalized\n",
      "[546 114]\n",
      "[-546 -114] normalized\n",
      "[669 816]\n",
      "[-669 276] normalized\n",
      "[1374 216]\n",
      "[414 -216] normalized\n",
      "[1638 234]\n",
      "[678 -234] normalized\n",
      "[480 786]\n",
      "[-480 246] normalized\n",
      "[288 483]\n",
      "[-288 -483] normalized\n",
      "[1491 264]\n",
      "[531 -264] normalized\n",
      "[1611 219]\n",
      "[651 -219] normalized\n",
      "[984 69]\n",
      "[24 -69] normalized\n",
      "[951 990]\n",
      "[-951 450] normalized\n",
      "[1233 954]\n",
      "[273 414] normalized\n",
      "[1242 978]\n",
      "[282 438] normalized\n",
      "[372 285]\n",
      "[-372 -285] normalized\n",
      "[1401 183]\n",
      "[441 -183] normalized\n",
      "[525 114]\n",
      "[-525 -114] normalized\n",
      "[306 411]\n",
      "[-306 -411] normalized\n",
      "[645 216]\n",
      "[-645 -216] normalized\n",
      "[1047 111]\n",
      "[87 -111] normalized\n",
      "[249 768]\n",
      "[-249 228] normalized\n",
      "[768 876]\n",
      "[-768 336] normalized\n",
      "[1101 144]\n",
      "[141 -144] normalized\n",
      "[771 987]\n",
      "[-771 447] normalized\n",
      "[1053 90]\n",
      "[93 -90] normalized\n",
      "[1431 159]\n",
      "[471 -159] normalized\n",
      "[636 81]\n",
      "[-636 -81] normalized\n",
      "[1263 87]\n",
      "[303 -87] normalized\n",
      "[1404 234]\n",
      "[444 -234] normalized\n",
      "[1797 495]\n",
      "[837 -495] normalized\n",
      "[1713 585]\n",
      "[753 45] normalized\n",
      "[1287 180]\n",
      "[327 -180] normalized\n",
      "[1590 825]\n",
      "[630 285] normalized\n",
      "[1311 150]\n",
      "[351 -150] normalized\n",
      "[1758 555]\n",
      "[798 15] normalized\n",
      "[606 705]\n",
      "[-606 165] normalized\n",
      "[696 78]\n",
      "[-696 -78] normalized\n",
      "[726 1002]\n",
      "[-726 462] normalized\n",
      "[1323 201]\n",
      "[363 -201] normalized\n",
      "[1701 387]\n",
      "[741 -387] normalized\n",
      "[765 309]\n",
      "[-765 -309] normalized\n",
      "[1332 105]\n",
      "[372 -105] normalized\n",
      "[585 114]\n",
      "[-585 -114] normalized\n",
      "[1434 171]\n",
      "[474 -171] normalized\n",
      "[1305 87]\n",
      "[345 -87] normalized\n",
      "[1836 702]\n",
      "[876 162] normalized\n",
      "[1425 156]\n",
      "[465 -156] normalized\n",
      "[909 981]\n",
      "[-909 441] normalized\n",
      "[1554 258]\n",
      "[594 -258] normalized\n",
      "[1323 870]\n",
      "[363 330] normalized\n",
      "[738 981]\n",
      "[-738 441] normalized\n",
      "[582 132]\n",
      "[-582 -132] normalized\n",
      "[1140 48]\n",
      "[180 -48] normalized\n",
      "[567 810]\n",
      "[-567 270] normalized\n",
      "[807 1050]\n",
      "[-807 510] normalized\n",
      "[1317 102]\n",
      "[357 -102] normalized\n",
      "[1599 648]\n",
      "[639 108] normalized\n",
      "[1425 132]\n",
      "[465 -132] normalized\n",
      "[957 114]\n",
      "[-957 -114] normalized\n",
      "[1656 396]\n",
      "[696 -396] normalized\n",
      "[1788 687]\n",
      "[828 147] normalized\n",
      "[987 753]\n",
      "[27 213] normalized\n",
      "[1287 147]\n",
      "[327 -147] normalized\n",
      "[1800 567]\n",
      "[840 27] normalized\n",
      "[1056 939]\n",
      "[96 399] normalized\n",
      "[1707 639]\n",
      "[747 99] normalized\n",
      "[1800 402]\n",
      "[840 -402] normalized\n",
      "[1164 96]\n",
      "[204 -96] normalized\n",
      "[1542 243]\n",
      "[582 -243] normalized\n",
      "[1428 870]\n",
      "[468 330] normalized\n",
      "[567 138]\n",
      "[-567 -138] normalized\n",
      "[744 261]\n",
      "[-744 -261] normalized\n",
      "[1029 993]\n",
      "[69 453] normalized\n",
      "[1467 348]\n",
      "[507 -348] normalized\n",
      "[696 1026]\n",
      "[-696 486] normalized\n",
      "[1230 123]\n",
      "[270 -123] normalized\n",
      "[405 852]\n",
      "[-405 312] normalized\n",
      "[1473 876]\n",
      "[513 336] normalized\n",
      "[333 225]\n",
      "[-333 -225] normalized\n",
      "[495 150]\n",
      "[-495 -150] normalized\n",
      "[969 948]\n",
      "[9 408] normalized\n",
      "[342 477]\n",
      "[-342 -477] normalized\n",
      "[765 93]\n",
      "[-765 -93] normalized\n",
      "[1587 303]\n",
      "[627 -303] normalized\n",
      "[1176 96]\n",
      "[216 -96] normalized\n",
      "[1020 945]\n",
      "[60 405] normalized\n",
      "[1308 93]\n",
      "[348 -93] normalized\n",
      "[1557 888]\n",
      "[597 348] normalized\n",
      "[1368 174]\n",
      "[408 -174] normalized\n",
      "[1461 126]\n",
      "[501 -126] normalized\n",
      "[801 1017]\n",
      "[-801 477] normalized\n",
      "[1659 597]\n",
      "[699 57] normalized\n",
      "[1140 93]\n",
      "[180 -93] normalized\n",
      "[384 657]\n",
      "[-384 117] normalized\n",
      "[426 156]\n",
      "[-426 -156] normalized\n",
      "[1428 99]\n",
      "[468 -99] normalized\n",
      "[1152 99]\n",
      "[192 -99] normalized\n",
      "[1611 378]\n",
      "[651 -378] normalized\n",
      "[744 978]\n",
      "[-744 438] normalized\n",
      "[1536 651]\n",
      "[576 111] normalized\n",
      "[1263 141]\n",
      "[303 -141] normalized\n",
      "[1479 129]\n",
      "[519 -129] normalized\n",
      "[546 69]\n",
      "[-546 -69] normalized\n",
      "[516 225]\n",
      "[-516 -225] normalized\n",
      "[1278 285]\n",
      "[318 -285] normalized\n",
      "[966 933]\n",
      "[6 393] normalized\n",
      "[1716 537]\n",
      "[756 -537] normalized\n",
      "[1839 765]\n",
      "[879 225] normalized\n",
      "[1638 315]\n",
      "[678 -315] normalized\n",
      "[429 165]\n",
      "[-429 -165] normalized\n",
      "[1239 72]\n",
      "[279 -72] normalized\n",
      "[1326 843]\n",
      "[366 303] normalized\n",
      "[1107 336]\n",
      "[147 -336] normalized\n",
      "[1140 147]\n",
      "[180 -147] normalized\n",
      "[1710 696]\n",
      "[750 156] normalized\n",
      "[732 84]\n",
      "[-732 -84] normalized\n",
      "[1119 132]\n",
      "[159 -132] normalized\n",
      "[396 258]\n",
      "[-396 -258] normalized\n",
      "[201 639]\n",
      "[-201 99] normalized\n",
      "[1335 126]\n",
      "[375 -126] normalized\n",
      "[432 351]\n",
      "[-432 -351] normalized\n",
      "[1470 855]\n",
      "[510 315] normalized\n",
      "[930 909]\n",
      "[-930 369] normalized\n",
      "[774 117]\n",
      "[-774 -117] normalized\n",
      "[1698 705]\n",
      "[738 165] normalized\n",
      "[648 855]\n",
      "[-648 315] normalized\n",
      "[1482 828]\n",
      "[522 288] normalized\n",
      "[264 756]\n",
      "[-264 216] normalized\n",
      "[996 216]\n",
      "[36 -216] normalized\n",
      "[342 816]\n",
      "[-342 276] normalized\n",
      "[1509 825]\n",
      "[549 285] normalized\n",
      "[180 555]\n",
      "[-180 15] normalized\n",
      "[750 81]\n",
      "[-750 -81] normalized\n",
      "[1644 825]\n",
      "[684 285] normalized\n",
      "[873 150]\n",
      "[-873 -150] normalized\n",
      "[48 597]\n",
      "[-48 57] normalized\n",
      "[1728 756]\n",
      "[768 216] normalized\n",
      "[1650 747]\n",
      "[690 207] normalized\n",
      "[1296 168]\n",
      "[336 -168] normalized\n",
      "[1362 126]\n",
      "[402 -126] normalized\n",
      "[522 105]\n",
      "[-522 -105] normalized\n",
      "[1242 117]\n",
      "[282 -117] normalized\n",
      "[975 1002]\n",
      "[15 462] normalized\n",
      "[600 216]\n",
      "[-600 -216] normalized\n",
      "[1485 252]\n",
      "[525 -252] normalized\n",
      "[1506 144]\n",
      "[546 -144] normalized\n",
      "[1041 120]\n",
      "[81 -120] normalized\n",
      "[1359 159]\n",
      "[399 -159] normalized\n",
      "[291 837]\n",
      "[-291 297] normalized\n",
      "[945 93]\n",
      "[-945 -93] normalized\n",
      "[729 96]\n",
      "[-729 -96] normalized\n",
      "[1173 906]\n",
      "[213 366] normalized\n",
      "[834 147]\n",
      "[-834 -147] normalized\n",
      "[714 999]\n",
      "[-714 459] normalized\n",
      "[636 858]\n",
      "[-636 318] normalized\n",
      "[744 372]\n",
      "[-744 -372] normalized\n",
      "[1365 180]\n",
      "[405 -180] normalized\n",
      "[1080 84]\n",
      "[120 -84] normalized\n",
      "[1062 1014]\n",
      "[102 474] normalized\n",
      "(128, 360, 640, 3) (128, 2)\n"
     ]
    }
   ],
   "source": [
    "X, y = create_input()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:20:54.290889500Z",
     "start_time": "2024-06-26T21:20:53.408833100Z"
    }
   },
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 953ms/step - loss: 453050.5000 - val_loss: 195647.4062\n",
      "Epoch 2/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 874ms/step - loss: 165213.6094 - val_loss: 177615.7344\n",
      "Epoch 3/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 894ms/step - loss: 133957.4844 - val_loss: 150834.0312\n",
      "Epoch 4/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 891ms/step - loss: 111931.4531 - val_loss: 147836.6562\n",
      "Epoch 5/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 939ms/step - loss: 95340.2344 - val_loss: 140455.5938\n",
      "Epoch 6/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 889ms/step - loss: 62191.3203 - val_loss: 145608.9219\n",
      "Epoch 7/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 854ms/step - loss: 40861.3828 - val_loss: 147992.5000\n",
      "Epoch 8/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 948ms/step - loss: 35584.3125 - val_loss: 153237.4688\n",
      "Epoch 9/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 894ms/step - loss: 24880.5605 - val_loss: 135535.1719\n",
      "Epoch 10/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 885ms/step - loss: 19461.7227 - val_loss: 140572.5312\n",
      "Epoch 11/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 823ms/step - loss: 15685.2227 - val_loss: 141328.1562\n",
      "Epoch 12/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 903ms/step - loss: 13720.9834 - val_loss: 143542.9688\n",
      "Epoch 13/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 925ms/step - loss: 9225.3457 - val_loss: 149005.0000\n",
      "Epoch 14/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 898ms/step - loss: 7219.3066 - val_loss: 146111.8750\n",
      "Epoch 15/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 881ms/step - loss: 5405.4688 - val_loss: 140914.9375\n",
      "Epoch 16/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 869ms/step - loss: 4865.8706 - val_loss: 142124.2031\n",
      "Epoch 17/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 966ms/step - loss: 3380.7920 - val_loss: 137869.2812\n",
      "Epoch 18/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 881ms/step - loss: 3450.7473 - val_loss: 142435.3438\n",
      "Epoch 19/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 911ms/step - loss: 2668.1714 - val_loss: 136825.0312\n",
      "Epoch 20/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 867ms/step - loss: 1653.6165 - val_loss: 142524.5625\n",
      "Epoch 21/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 818ms/step - loss: 2103.6919 - val_loss: 135056.2344\n",
      "Epoch 22/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 815ms/step - loss: 1260.5664 - val_loss: 141689.1719\n",
      "Epoch 23/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 824ms/step - loss: 1063.9010 - val_loss: 137633.5000\n",
      "Epoch 24/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 837ms/step - loss: 782.2133 - val_loss: 138320.7500\n",
      "Epoch 25/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 948ms/step - loss: 1221.8364 - val_loss: 138313.7969\n",
      "Epoch 26/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 925ms/step - loss: 684.1906 - val_loss: 135926.8594\n",
      "Epoch 27/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 988ms/step - loss: 1075.7252 - val_loss: 141916.0000\n",
      "Epoch 28/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 864ms/step - loss: 715.0464 - val_loss: 133906.6875\n",
      "Epoch 29/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 819ms/step - loss: 1187.8636 - val_loss: 141219.7188\n",
      "Epoch 30/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 815ms/step - loss: 611.0978 - val_loss: 135470.7188\n",
      "Epoch 31/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 819ms/step - loss: 502.6218 - val_loss: 138316.3750\n",
      "Epoch 32/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 820ms/step - loss: 632.8478 - val_loss: 138221.2188\n",
      "Epoch 33/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 818ms/step - loss: 710.3262 - val_loss: 137738.7500\n",
      "Epoch 34/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 809ms/step - loss: 337.2365 - val_loss: 140207.2188\n",
      "Epoch 35/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 832ms/step - loss: 271.0202 - val_loss: 136686.5156\n",
      "Epoch 36/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 1s/step - loss: 331.4567 - val_loss: 139325.9844\n",
      "Epoch 37/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 1s/step - loss: 393.3777 - val_loss: 138689.6875\n",
      "Epoch 38/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 915ms/step - loss: 305.5374 - val_loss: 138022.8125\n",
      "Epoch 39/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 880ms/step - loss: 168.4124 - val_loss: 138638.0312\n",
      "Epoch 40/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 827ms/step - loss: 187.1479 - val_loss: 137920.3125\n",
      "Epoch 41/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 823ms/step - loss: 411.4688 - val_loss: 138499.3438\n",
      "Epoch 42/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 848ms/step - loss: 249.7206 - val_loss: 138644.6875\n",
      "Epoch 43/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 824ms/step - loss: 116.0032 - val_loss: 138898.7812\n",
      "Epoch 44/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 827ms/step - loss: 113.6582 - val_loss: 137963.5938\n",
      "Epoch 45/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 836ms/step - loss: 186.2120 - val_loss: 138383.3438\n",
      "Epoch 46/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 830ms/step - loss: 123.0800 - val_loss: 139183.8125\n",
      "Epoch 47/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 833ms/step - loss: 181.1565 - val_loss: 138607.2188\n",
      "Epoch 48/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 841ms/step - loss: 148.9946 - val_loss: 138393.4375\n",
      "Epoch 49/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 841ms/step - loss: 65.5164 - val_loss: 139594.1875\n",
      "Epoch 50/50\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 855ms/step - loss: 66.5130 - val_loss: 139146.1562\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x11d4af58ec0>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:24:05.840209800Z",
     "start_time": "2024-06-26T21:21:10.980291200Z"
    }
   },
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('mouse_explore_fhd_normalized.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:24:09.989477500Z",
     "start_time": "2024-06-26T21:24:08.494243800Z"
    }
   },
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 -285\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 117ms/step\n",
      "1183 62 \n",
      " 318 -285\n",
      "879 225\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "1607 739 \n",
      " 879 225\n",
      "-522 -105\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "555 185 \n",
      " -522 -105\n",
      "-807 510\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "165 661 \n",
      " -807 510\n",
      "-384 117\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "706 663 \n",
      " -384 117\n",
      "444 -234\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "1094 63 \n",
      " 444 -234\n",
      "303 -141\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "1257 169 \n",
      " 303 -141\n",
      "-738 441\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "351 819 \n",
      " -738 441\n",
      "576 111\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "16 548 \n",
      " 576 111\n",
      "282 -117\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "50 146 \n",
      " 282 -117\n",
      "-645 -216\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "742 297 \n",
      " -645 -216\n",
      "627 -303\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "1197 12 \n",
      " 627 -303\n",
      "-372 -285\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "245 146 \n",
      " -372 -285\n",
      "747 99\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "1373 681 \n",
      " 747 99\n",
      "-771 447\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "36 654 \n",
      " -771 447\n",
      "837 -495\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "984 609 \n",
      " 837 -495\n",
      "-264 216\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "244 762 \n",
      " -264 216\n",
      "81 -120\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "984 407 \n",
      " 81 -120\n",
      "651 -378\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "1488 79 \n",
      " 651 -378\n",
      "441 -183\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "1398 113 \n",
      " 441 -183\n"
     ]
    }
   ],
   "source": [
    "model_rap = tf.keras.models.load_model('mouse_explore_fhd_normalized.h5')\n",
    "\n",
    "\n",
    "for n in range(20):\n",
    "    x_real, y_real = int(y_val[n][0]), int(y_val[n][1])\n",
    "    print(x_real, y_real)\n",
    "    img = np.asarray(X_val[n])\n",
    "\n",
    "    tbp = np.expand_dims(img, axis=0)\n",
    "    img = cv2.resize(img,(1920,1080))\n",
    "    predictions = model_rap.predict(tbp)\n",
    "    x, y = int(predictions[0][0]), int(predictions[0][1])\n",
    "    if x < 0:\n",
    "        x = -x \n",
    "    else:\n",
    "        x = x + 960\n",
    "    \n",
    "    if y < 0:\n",
    "        y = -y\n",
    "    else:\n",
    "        y = y + 540\n",
    "    \n",
    "    print(x, y, \"\\n\",x_real, y_real)\n",
    "    \n",
    "    cv2.circle(img, (x,y), 10, (0,0,255), -1)\n",
    "    cv2.circle(img, (x_real, y_real), 10, (255,255,255), -1)\n",
    "    \n",
    "    cv2.imshow('ss', img)\n",
    "    cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyWindow('ss')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:24:48.358747Z",
     "start_time": "2024-06-26T21:24:10.089574200Z"
    }
   },
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 1s/step - loss: 2466981.0000 - val_loss: 1351475.7500\n",
      "Epoch 2/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 943ms/step - loss: 1013773.5625 - val_loss: 221797.5000\n",
      "Epoch 3/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 878ms/step - loss: 167532.5938 - val_loss: 207102.3125\n",
      "Epoch 4/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 871ms/step - loss: 123114.7422 - val_loss: 225627.2500\n",
      "Epoch 5/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 910ms/step - loss: 121374.1250 - val_loss: 190306.0312\n",
      "Epoch 6/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 1s/step - loss: 122928.6406 - val_loss: 199820.6719\n",
      "Epoch 7/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 903ms/step - loss: 108252.2812 - val_loss: 195921.4375\n",
      "Epoch 8/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 872ms/step - loss: 103571.0703 - val_loss: 183029.7500\n",
      "Epoch 9/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 869ms/step - loss: 84680.7656 - val_loss: 193496.6875\n",
      "Epoch 10/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 894ms/step - loss: 81365.6562 - val_loss: 184376.2188\n",
      "Epoch 11/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 924ms/step - loss: 67383.7109 - val_loss: 183592.3125\n",
      "Epoch 12/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 856ms/step - loss: 58798.5547 - val_loss: 185833.7812\n",
      "Epoch 13/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 864ms/step - loss: 52435.1758 - val_loss: 185340.8281\n",
      "Epoch 14/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 870ms/step - loss: 40395.0820 - val_loss: 185398.0781\n",
      "Epoch 15/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 879ms/step - loss: 33044.0742 - val_loss: 185145.3906\n",
      "Epoch 16/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 911ms/step - loss: 29236.4746 - val_loss: 185525.1250\n",
      "Epoch 17/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 908ms/step - loss: 20831.0605 - val_loss: 185959.9531\n",
      "Epoch 18/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 867ms/step - loss: 15945.7607 - val_loss: 186201.5312\n",
      "Epoch 19/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 882ms/step - loss: 12561.5381 - val_loss: 185729.6094\n",
      "Epoch 20/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 872ms/step - loss: 8795.4375 - val_loss: 185605.7500\n",
      "Epoch 21/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 863ms/step - loss: 7169.1895 - val_loss: 185036.2344\n",
      "Epoch 22/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 854ms/step - loss: 6128.5806 - val_loss: 183674.4375\n",
      "Epoch 23/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 865ms/step - loss: 4165.5654 - val_loss: 182131.9062\n",
      "Epoch 24/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 860ms/step - loss: 2670.3513 - val_loss: 181907.1875\n",
      "Epoch 25/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 856ms/step - loss: 2299.2744 - val_loss: 182372.0625\n",
      "Epoch 26/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 851ms/step - loss: 1705.9655 - val_loss: 182574.0000\n",
      "Epoch 27/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 872ms/step - loss: 1484.7703 - val_loss: 182575.0625\n",
      "Epoch 28/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 972ms/step - loss: 826.0281 - val_loss: 182909.6250\n",
      "Epoch 29/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 872ms/step - loss: 736.0970 - val_loss: 182200.6562\n",
      "Epoch 30/30\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 1s/step - loss: 542.2997 - val_loss: 182130.7656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_rap = tf.keras.models.load_model('mouse_explore_fhd2.h5')\n",
    "model_rap.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "\n",
    "model_rap.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))\n",
    "model_rap.save('mouse_explore_fhd2.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:15:11.000769400Z",
     "start_time": "2024-06-26T21:13:19.845007700Z"
    }
   },
   "execution_count": 41
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
