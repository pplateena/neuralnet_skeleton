{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Classification model training script\n",
    "Goal of model is to classify action between attack/explore"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from utility_modules.torch_toolkit import ClassificationCNN, ClassificationCNN_type2, ClassificationDataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T18:05:03.512220400Z",
     "start_time": "2024-08-14T18:04:57.345908200Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dataset, with 7206 images\n",
      "Compose(\n",
      "    ToTensor()\n",
      "    Resize(size=(360, 640), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "folder_paths = ['augmented_data/', 'classification_data/', 'predicted_data/']\n",
    "\n",
    "dataset = ClassificationDataset(folder_paths)\n",
    "print(f'created dataset, with {len(dataset)} images')\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T18:05:03.545773Z",
     "start_time": "2024-08-14T18:05:03.516187Z"
    }
   },
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## CNN structure:\n",
    "Model consists of 3 convolutional layers, 1 max pooling layer to lower computation cost, and 3 fully connected layers, with output layer of 2 neurons attack/explore. <br>\n",
    "\n",
    "The input for the model is 640x360 tensor after convolutional layers results in 64 feature maps with size 45x80(0.125 * 640x480)."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "model = ClassificationCNN().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T16:16:15.829341100Z",
     "start_time": "2024-08-14T16:16:14.617828200Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6453\n",
      "Epoch [2/5], Loss: 0.6118\n",
      "Epoch [3/5], Loss: 0.5946\n",
      "Epoch [4/5], Loss: 0.5853\n",
      "Epoch [5/5], Loss: 0.5728\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T17:35:50.899435500Z",
     "start_time": "2024-08-14T16:16:18.053509Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6553\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        predicted = torch.round(torch.sigmoid(outputs))\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T17:54:46.053750800Z",
     "start_time": "2024-08-14T17:53:52.452138700Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Further training of already existent model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'class_torch_7kds.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T17:56:16.394113900Z",
     "start_time": "2024-08-14T17:56:15.077223600Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Type 2 classification model\n",
    "Lowered neurons in layer from 512 to 128, and added extra fully connected layer. Type 2 model has 4 fully connected layers with 128, 64, 32, 2 neurons respectfully."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "model = ClassificationCNN_type2().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T18:05:14.833892500Z",
     "start_time": "2024-08-14T18:05:14.471181600Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6343\n",
      "Epoch [2/5], Loss: 0.6090\n",
      "Epoch [3/5], Loss: 0.6035\n",
      "Epoch [4/5], Loss: 0.5952\n",
      "Epoch [5/5], Loss: 0.5859\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T18:16:28.803968500Z",
     "start_time": "2024-08-14T18:05:34.410899400Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6692\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        predicted = torch.round(torch.sigmoid(outputs))\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T18:16:56.494825400Z",
     "start_time": "2024-08-14T18:16:33.655071300Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Type 2 shows good results!!\n",
    "Each train epoch is 7 times faster, takes 2.2 minutes. Accuracy is slightly higher, so I will try to train the model few more epochs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.5820\n",
      "Epoch [2/15], Loss: 0.5711\n",
      "Epoch [3/15], Loss: 0.5582\n",
      "Epoch [4/15], Loss: 0.5505\n",
      "Epoch [5/15], Loss: 0.5417\n",
      "Epoch [6/15], Loss: 0.5389\n",
      "Epoch [7/15], Loss: 0.5331\n",
      "Epoch [8/15], Loss: 0.5309\n",
      "Epoch [9/15], Loss: 0.5313\n",
      "Epoch [10/15], Loss: 0.5279\n",
      "Epoch [11/15], Loss: 0.5268\n",
      "Epoch [12/15], Loss: 0.5266\n",
      "Epoch [13/15], Loss: 0.5288\n",
      "Epoch [14/15], Loss: 0.5274\n",
      "Epoch [15/15], Loss: 0.5279\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T18:52:49.157920700Z",
     "start_time": "2024-08-14T18:20:52.046986Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6796\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        predicted = torch.round(torch.sigmoid(outputs))\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T18:54:58.633034100Z",
     "start_time": "2024-08-14T18:54:36.059616800Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'class_torch_type2.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T18:56:59.565486600Z",
     "start_time": "2024-08-14T18:56:59.269252Z"
    }
   },
   "execution_count": 8
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
