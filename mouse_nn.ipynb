{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:45:02.139627200Z",
     "start_time": "2024-06-26T21:45:02.092843800Z"
    }
   },
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_input():\n",
    "    X = []\n",
    "    y = []\n",
    "    df = pd.read_csv(\"classification_data/attack_img/attack_data.csv\")\n",
    "    shuffled_df = df.sample(len(df))\n",
    "\n",
    "    print(shuffled_df.head)\n",
    "    s = 0\n",
    "    for entry in shuffled_df.values:\n",
    "        s += 1\n",
    "        # print(s)\n",
    "        entry_img = cv2.imread(f\"classification_data/attack_img/{entry[0]}\")\n",
    "\n",
    "        prepared_y = np.delete(entry,0) * 3\n",
    "        print(prepared_y)\n",
    "        if prepared_y[0] >= 960:\n",
    "            prepared_y[0] = prepared_y[0] - 960\n",
    "        else:\n",
    "            prepared_y[0] = -prepared_y[0]\n",
    "            \n",
    "        if prepared_y[1] >= 540:\n",
    "            prepared_y[1] = prepared_y[1] - 540\n",
    "        else:\n",
    "            prepared_y[1] = -prepared_y[1]\n",
    "        \n",
    "        X.append(entry_img)\n",
    "        y.append(prepared_y)\n",
    "\n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).astype(np.float32)\n",
    "    return X, y\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:45:03.304770600Z",
     "start_time": "2024-06-26T21:45:03.289215600Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compile_model():\n",
    "    image_width, image_height, channels = 640, 360, 3  # Assuming RGB images\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(image_height, image_width, channels)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = compile_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:45:08.589895900Z",
     "start_time": "2024-06-26T21:45:08.235746900Z"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:45:09.434523200Z",
     "start_time": "2024-06-26T21:45:09.412568500Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            filename    x    y\n",
      "147  attack_147.jpg  384  107\n",
      "316  attack_316.jpg  401  138\n",
      "363  attack_363.jpg  178   54\n",
      "207  attack_207.jpg  395  214\n",
      "9      attack_9.jpg  281   52\n",
      "..              ...  ...  ...\n",
      "198  attack_198.jpg  378   63\n",
      "159  attack_159.jpg  364  158\n",
      "371  attack_371.jpg  293   38\n",
      "237  attack_237.jpg  219  103\n",
      "4      attack_4.jpg  402   99\n",
      "\n",
      "[395 rows x 3 columns]>\n",
      "[1152 321]\n",
      "[1203 414]\n",
      "[534 162]\n",
      "[1185 642]\n",
      "[843 156]\n",
      "[174 156]\n",
      "[1023 540]\n",
      "[552 150]\n",
      "[1197 336]\n",
      "[1158 453]\n",
      "[783 45]\n",
      "[1125 291]\n",
      "[1095 360]\n",
      "[1311 54]\n",
      "[726 744]\n",
      "[1161 414]\n",
      "[1155 198]\n",
      "[1125 393]\n",
      "[1050 117]\n",
      "[1110 591]\n",
      "[951 603]\n",
      "[954 591]\n",
      "[1056 606]\n",
      "[1209 537]\n",
      "[1158 252]\n",
      "[984 552]\n",
      "[1245 504]\n",
      "[1056 324]\n",
      "[1062 243]\n",
      "[1011 234]\n",
      "[1068 216]\n",
      "[1158 462]\n",
      "[1095 255]\n",
      "[705 447]\n",
      "[1428 783]\n",
      "[1113 297]\n",
      "[495 402]\n",
      "[1218 414]\n",
      "[972 279]\n",
      "[1125 312]\n",
      "[1050 261]\n",
      "[1188 288]\n",
      "[1194 246]\n",
      "[1257 57]\n",
      "[786 216]\n",
      "[1119 177]\n",
      "[1146 201]\n",
      "[1725 351]\n",
      "[1275 324]\n",
      "[1164 414]\n",
      "[1020 609]\n",
      "[330 354]\n",
      "[1107 195]\n",
      "[1095 594]\n",
      "[1341 519]\n",
      "[468 258]\n",
      "[1083 585]\n",
      "[1011 351]\n",
      "[1152 249]\n",
      "[798 267]\n",
      "[1305 231]\n",
      "[1068 213]\n",
      "[1128 243]\n",
      "[1227 501]\n",
      "[1089 600]\n",
      "[1056 495]\n",
      "[1152 393]\n",
      "[1146 414]\n",
      "[1074 306]\n",
      "[1071 531]\n",
      "[1350 606]\n",
      "[1050 597]\n",
      "[1128 102]\n",
      "[1002 159]\n",
      "[426 69]\n",
      "[1254 576]\n",
      "[747 393]\n",
      "[1245 732]\n",
      "[1011 267]\n",
      "[1230 375]\n",
      "[1149 117]\n",
      "[1650 474]\n",
      "[1179 513]\n",
      "[1041 609]\n",
      "[1170 414]\n",
      "[1119 576]\n",
      "[939 138]\n",
      "[1020 291]\n",
      "[1065 207]\n",
      "[1035 486]\n",
      "[1293 144]\n",
      "[1146 201]\n",
      "[1104 534]\n",
      "[1200 483]\n",
      "[1116 225]\n",
      "[1065 501]\n",
      "[1158 591]\n",
      "[783 537]\n",
      "[1167 57]\n",
      "[1086 633]\n",
      "[687 504]\n",
      "[1140 489]\n",
      "[1350 474]\n",
      "[1140 195]\n",
      "[1239 189]\n",
      "[1110 342]\n",
      "[690 369]\n",
      "[1170 459]\n",
      "[1425 288]\n",
      "[1005 648]\n",
      "[1107 417]\n",
      "[969 1020]\n",
      "[1089 561]\n",
      "[1062 210]\n",
      "[786 201]\n",
      "[1164 288]\n",
      "[1146 405]\n",
      "[582 912]\n",
      "[417 783]\n",
      "[1197 282]\n",
      "[1155 342]\n",
      "[573 900]\n",
      "[1206 336]\n",
      "[1068 507]\n",
      "[1410 228]\n",
      "[1089 120]\n",
      "[1002 267]\n",
      "[1059 183]\n",
      "[807 270]\n",
      "[1161 435]\n",
      "[1125 405]\n",
      "[1242 594]\n",
      "[1650 234]\n",
      "[393 714]\n",
      "[1377 591]\n",
      "[948 576]\n",
      "[1053 201]\n",
      "[657 399]\n",
      "[1086 408]\n",
      "[1125 324]\n",
      "[1104 432]\n",
      "[1686 366]\n",
      "[642 423]\n",
      "[1017 246]\n",
      "[846 627]\n",
      "[1200 330]\n",
      "[1179 540]\n",
      "[1110 186]\n",
      "[1341 702]\n",
      "[804 345]\n",
      "[1182 282]\n",
      "[1047 327]\n",
      "[987 180]\n",
      "[1104 267]\n",
      "[1092 207]\n",
      "[1176 483]\n",
      "[957 162]\n",
      "[504 501]\n",
      "[1062 138]\n",
      "[1224 567]\n",
      "[861 546]\n",
      "[1122 636]\n",
      "[1431 63]\n",
      "[1467 63]\n",
      "[1275 252]\n",
      "[1215 648]\n",
      "[1254 459]\n",
      "[1224 192]\n",
      "[675 471]\n",
      "[1152 288]\n",
      "[837 273]\n",
      "[1029 210]\n",
      "[1122 252]\n",
      "[987 624]\n",
      "[1059 243]\n",
      "[1050 342]\n",
      "[1029 216]\n",
      "[1179 195]\n",
      "[840 567]\n",
      "[1146 243]\n",
      "[1293 189]\n",
      "[1077 228]\n",
      "[570 384]\n",
      "[1020 207]\n",
      "[1023 471]\n",
      "[1176 519]\n",
      "[840 294]\n",
      "[1020 399]\n",
      "[1236 192]\n",
      "[645 126]\n",
      "[1341 441]\n",
      "[984 183]\n",
      "[1134 258]\n",
      "[1065 144]\n",
      "[1227 408]\n",
      "[1398 57]\n",
      "[186 267]\n",
      "[1062 435]\n",
      "[549 141]\n",
      "[1314 387]\n",
      "[1068 207]\n",
      "[1350 645]\n",
      "[1032 381]\n",
      "[1179 321]\n",
      "[735 135]\n",
      "[1146 402]\n",
      "[1215 516]\n",
      "[615 327]\n",
      "[1377 723]\n",
      "[816 108]\n",
      "[1077 606]\n",
      "[1149 258]\n",
      "[1200 333]\n",
      "[519 261]\n",
      "[1083 213]\n",
      "[1116 648]\n",
      "[423 93]\n",
      "[1128 270]\n",
      "[1302 306]\n",
      "[1203 465]\n",
      "[1347 465]\n",
      "[1104 222]\n",
      "[1005 756]\n",
      "[1146 171]\n",
      "[1104 270]\n",
      "[375 621]\n",
      "[1137 354]\n",
      "[1116 387]\n",
      "[1065 396]\n",
      "[861 135]\n",
      "[1113 567]\n",
      "[1140 495]\n",
      "[1107 318]\n",
      "[1119 273]\n",
      "[1113 429]\n",
      "[1158 315]\n",
      "[1080 567]\n",
      "[846 690]\n",
      "[927 615]\n",
      "[1152 270]\n",
      "[1065 516]\n",
      "[783 384]\n",
      "[1389 123]\n",
      "[1230 165]\n",
      "[795 789]\n",
      "[279 240]\n",
      "[1104 330]\n",
      "[1128 297]\n",
      "[1080 282]\n",
      "[948 537]\n",
      "[1095 180]\n",
      "[1026 258]\n",
      "[1071 267]\n",
      "[1125 252]\n",
      "[1128 360]\n",
      "[1206 474]\n",
      "[1170 285]\n",
      "[831 414]\n",
      "[1218 375]\n",
      "[1191 519]\n",
      "[1305 312]\n",
      "[1230 486]\n",
      "[1026 219]\n",
      "[1479 258]\n",
      "[1224 318]\n",
      "[1101 222]\n",
      "[1119 312]\n",
      "[1125 339]\n",
      "[1110 645]\n",
      "[1197 474]\n",
      "[1119 582]\n",
      "[1128 564]\n",
      "[1338 741]\n",
      "[1110 570]\n",
      "[1128 555]\n",
      "[828 102]\n",
      "[1089 195]\n",
      "[1356 429]\n",
      "[1104 246]\n",
      "[750 114]\n",
      "[1188 267]\n",
      "[1107 198]\n",
      "[1077 375]\n",
      "[1110 333]\n",
      "[1098 246]\n",
      "[1152 312]\n",
      "[1176 444]\n",
      "[1146 312]\n",
      "[1065 180]\n",
      "[642 165]\n",
      "[768 768]\n",
      "[1299 300]\n",
      "[1191 294]\n",
      "[1038 135]\n",
      "[579 135]\n",
      "[1050 228]\n",
      "[1134 246]\n",
      "[1059 204]\n",
      "[690 465]\n",
      "[1275 768]\n",
      "[1146 261]\n",
      "[1152 666]\n",
      "[1035 162]\n",
      "[1086 573]\n",
      "[1008 222]\n",
      "[1200 474]\n",
      "[891 636]\n",
      "[1239 474]\n",
      "[1104 552]\n",
      "[1023 45]\n",
      "[1077 513]\n",
      "[1056 303]\n",
      "[714 420]\n",
      "[1008 213]\n",
      "[1206 405]\n",
      "[1341 87]\n",
      "[1065 174]\n",
      "[1257 708]\n",
      "[633 99]\n",
      "[1107 237]\n",
      "[1053 132]\n",
      "[1149 117]\n",
      "[675 21]\n",
      "[1281 195]\n",
      "[1008 177]\n",
      "[1182 510]\n",
      "[1209 537]\n",
      "[525 102]\n",
      "[825 111]\n",
      "[288 201]\n",
      "[1149 303]\n",
      "[1065 228]\n",
      "[1152 360]\n",
      "[1185 222]\n",
      "[1353 126]\n",
      "[1176 282]\n",
      "[1419 876]\n",
      "[1086 390]\n",
      "[1143 462]\n",
      "[1101 270]\n",
      "[1155 270]\n",
      "[1095 306]\n",
      "[1140 207]\n",
      "[1086 324]\n",
      "[1170 624]\n",
      "[1077 348]\n",
      "[810 249]\n",
      "[1101 576]\n",
      "[282 708]\n",
      "[1062 369]\n",
      "[1017 663]\n",
      "[1116 228]\n",
      "[657 237]\n",
      "[285 816]\n",
      "[249 294]\n",
      "[1167 330]\n",
      "[1047 588]\n",
      "[1056 300]\n",
      "[1077 567]\n",
      "[1116 303]\n",
      "[1200 513]\n",
      "[948 579]\n",
      "[1170 291]\n",
      "[1089 570]\n",
      "[1329 375]\n",
      "[1083 396]\n",
      "[891 513]\n",
      "[1152 339]\n",
      "[741 384]\n",
      "[1311 255]\n",
      "[1086 315]\n",
      "[1086 201]\n",
      "[1176 360]\n",
      "[1155 246]\n",
      "[1182 423]\n",
      "[393 267]\n",
      "[1155 252]\n",
      "[1065 204]\n",
      "[885 543]\n",
      "[777 444]\n",
      "[603 255]\n",
      "[1140 282]\n",
      "[1038 231]\n",
      "[1104 357]\n",
      "[1176 345]\n",
      "[1197 459]\n",
      "[1107 282]\n",
      "[1095 303]\n",
      "[1344 405]\n",
      "[1080 315]\n",
      "[1134 189]\n",
      "[1092 474]\n",
      "[879 114]\n",
      "[657 309]\n",
      "[1206 297]\n",
      "(316, 360, 640, 3) (316, 2)\n",
      "[ 117. -228.]\n"
     ]
    }
   ],
   "source": [
    "X, y = create_input()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(y_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:45:14.926997900Z",
     "start_time": "2024-06-26T21:45:11.912715900Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 1s/step - loss: 3293240.7500 - val_loss: 240838.6406\n",
      "Epoch 2/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1s/step - loss: 188229.0000 - val_loss: 72240.7266\n",
      "Epoch 3/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1s/step - loss: 87706.7109 - val_loss: 69411.2578\n",
      "Epoch 4/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1s/step - loss: 87884.2422 - val_loss: 72502.9531\n",
      "Epoch 5/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 68290.8203 - val_loss: 89909.0000\n",
      "Epoch 6/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 67115.5000 - val_loss: 72060.8125\n",
      "Epoch 7/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 978ms/step - loss: 47958.3789 - val_loss: 87524.8359\n",
      "Epoch 8/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 983ms/step - loss: 39011.6211 - val_loss: 80118.5312\n",
      "Epoch 9/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 989ms/step - loss: 29989.7832 - val_loss: 81336.6016\n",
      "Epoch 10/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 983ms/step - loss: 20672.7109 - val_loss: 85033.4922\n",
      "Epoch 11/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 969ms/step - loss: 13686.3555 - val_loss: 93527.5156\n",
      "Epoch 12/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 971ms/step - loss: 11336.5391 - val_loss: 84573.1172\n",
      "Epoch 13/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 972ms/step - loss: 5883.3511 - val_loss: 83135.6562\n",
      "Epoch 14/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 961ms/step - loss: 4268.1748 - val_loss: 83317.8203\n",
      "Epoch 15/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 984ms/step - loss: 2685.0417 - val_loss: 82537.2031\n",
      "Epoch 16/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 987ms/step - loss: 1986.8190 - val_loss: 83518.7031\n",
      "Epoch 17/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 972ms/step - loss: 1697.1885 - val_loss: 81355.7422\n",
      "Epoch 18/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 973ms/step - loss: 1262.5427 - val_loss: 83539.2812\n",
      "Epoch 19/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 976ms/step - loss: 1151.4912 - val_loss: 82744.6719\n",
      "Epoch 20/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 980ms/step - loss: 799.2991 - val_loss: 81520.3359\n",
      "Epoch 21/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 982ms/step - loss: 588.2455 - val_loss: 80597.6562\n",
      "Epoch 22/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 991ms/step - loss: 506.5617 - val_loss: 80767.3203\n",
      "Epoch 23/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 999ms/step - loss: 508.6995 - val_loss: 82325.3672\n",
      "Epoch 24/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 986ms/step - loss: 586.2548 - val_loss: 81058.9766\n",
      "Epoch 25/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 975ms/step - loss: 273.6394 - val_loss: 80756.0781\n",
      "Epoch 26/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 978ms/step - loss: 390.1154 - val_loss: 80995.1016\n",
      "Epoch 27/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 963ms/step - loss: 391.8642 - val_loss: 81195.7109\n",
      "Epoch 28/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 969ms/step - loss: 426.2192 - val_loss: 81626.1875\n",
      "Epoch 29/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 972ms/step - loss: 490.5439 - val_loss: 83014.2812\n",
      "Epoch 30/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 983ms/step - loss: 1239.2854 - val_loss: 82926.3828\n",
      "Epoch 31/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 965ms/step - loss: 1370.0753 - val_loss: 81420.5938\n",
      "Epoch 32/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 971ms/step - loss: 1836.8723 - val_loss: 83344.2656\n",
      "Epoch 33/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 988ms/step - loss: 4184.0015 - val_loss: 83580.7109\n",
      "Epoch 34/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 971ms/step - loss: 4544.3799 - val_loss: 86320.7578\n",
      "Epoch 35/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 983ms/step - loss: 4206.9897 - val_loss: 83381.8750\n",
      "Epoch 36/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 994ms/step - loss: 2672.2158 - val_loss: 81709.6328\n",
      "Epoch 37/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 982ms/step - loss: 1273.7932 - val_loss: 80483.2422\n",
      "Epoch 38/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 984ms/step - loss: 839.1276 - val_loss: 81537.5469\n",
      "Epoch 39/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 985ms/step - loss: 628.8232 - val_loss: 81352.7344\n",
      "Epoch 40/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 987ms/step - loss: 651.0259 - val_loss: 80740.8828\n",
      "Epoch 41/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 978ms/step - loss: 329.3198 - val_loss: 80991.0625\n",
      "Epoch 42/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 276.0554 - val_loss: 80539.1797\n",
      "Epoch 43/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 139.5141 - val_loss: 80799.5938\n",
      "Epoch 44/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 99.1382 - val_loss: 80508.1953\n",
      "Epoch 45/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 76.3574 - val_loss: 80591.1328\n",
      "Epoch 46/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 992ms/step - loss: 44.4172 - val_loss: 80581.1797\n",
      "Epoch 47/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 982ms/step - loss: 51.1897 - val_loss: 80392.8594\n",
      "Epoch 48/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 981ms/step - loss: 49.0801 - val_loss: 80216.0859\n",
      "Epoch 49/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 988ms/step - loss: 37.5263 - val_loss: 80322.9297\n",
      "Epoch 50/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 45.3978 - val_loss: 80377.9141\n",
      "Epoch 51/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 31.8599 - val_loss: 80644.1641\n",
      "Epoch 52/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 44.0430 - val_loss: 80228.1484\n",
      "Epoch 53/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 85.7262 - val_loss: 80566.0781\n",
      "Epoch 54/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 993ms/step - loss: 98.5768 - val_loss: 80714.4141\n",
      "Epoch 55/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 987ms/step - loss: 57.5645 - val_loss: 80230.9688\n",
      "Epoch 56/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 989ms/step - loss: 48.1149 - val_loss: 80549.0781\n",
      "Epoch 57/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 44.6933 - val_loss: 80649.2188\n",
      "Epoch 58/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 999ms/step - loss: 36.6963 - val_loss: 80461.0156\n",
      "Epoch 59/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 990ms/step - loss: 35.3641 - val_loss: 80397.0000\n",
      "Epoch 60/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 992ms/step - loss: 28.9608 - val_loss: 80255.0625\n",
      "Epoch 61/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 989ms/step - loss: 51.5044 - val_loss: 80372.7109\n",
      "Epoch 62/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 980ms/step - loss: 42.7290 - val_loss: 80704.1250\n",
      "Epoch 63/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 993ms/step - loss: 47.2445 - val_loss: 80528.8047\n",
      "Epoch 64/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 994ms/step - loss: 73.3013 - val_loss: 80467.6797\n",
      "Epoch 65/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 984ms/step - loss: 60.9112 - val_loss: 80692.9141\n",
      "Epoch 66/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 979ms/step - loss: 103.7270 - val_loss: 80799.4141\n",
      "Epoch 67/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 976ms/step - loss: 131.7564 - val_loss: 80521.0469\n",
      "Epoch 68/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 977ms/step - loss: 141.4866 - val_loss: 80811.6641\n",
      "Epoch 69/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 985ms/step - loss: 346.5057 - val_loss: 81660.5703\n",
      "Epoch 70/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 969ms/step - loss: 487.4732 - val_loss: 80981.6172\n",
      "Epoch 71/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - loss: 195.4243 - val_loss: 80119.7812\n",
      "Epoch 72/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 980ms/step - loss: 217.2857 - val_loss: 80727.6172\n",
      "Epoch 73/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 978ms/step - loss: 297.4319 - val_loss: 80163.7266\n",
      "Epoch 74/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 982ms/step - loss: 851.3073 - val_loss: 81563.5000\n",
      "Epoch 75/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 975ms/step - loss: 1462.6188 - val_loss: 80384.9766\n",
      "Epoch 76/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 976ms/step - loss: 1331.2148 - val_loss: 80964.8984\n",
      "Epoch 77/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 978ms/step - loss: 679.0724 - val_loss: 81872.6016\n",
      "Epoch 78/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 998ms/step - loss: 688.2836 - val_loss: 80169.0000\n",
      "Epoch 79/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 980ms/step - loss: 1151.0828 - val_loss: 79384.1953\n",
      "Epoch 80/80\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 968ms/step - loss: 2067.9475 - val_loss: 85618.2031\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x25c332a0080>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=80, validation_data=(X_val, y_val))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T21:58:50.073063100Z",
     "start_time": "2024-06-26T21:45:30.937284300Z"
    }
   },
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('mouse_attack_fhd_normalized.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T22:01:08.387745200Z",
     "start_time": "2024-06-26T22:01:06.726104200Z"
    }
   },
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 -267\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 220ms/step\n",
      "1089 215 \n",
      " 1011 267\n",
      "126 -201\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "1051 232 \n",
      " 1086 201\n",
      "120 -282\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "147 199 \n",
      " 1080 282\n",
      "-468 -258\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "982 120 \n",
      " 468 258\n",
      "174 -189\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "1102 151 \n",
      " 1134 189\n",
      "186 -171\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "985 54 \n",
      " 1146 171\n",
      "234 -246\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "1124 229 \n",
      " 1194 246\n",
      "153 -429\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "196 209 \n",
      " 1113 429\n",
      "105 -174\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "1027 162 \n",
      " 1065 174\n",
      "186 -405\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "1011 238 \n",
      " 1146 405\n",
      "198 -453\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "976 306 \n",
      " 1158 453\n",
      "-816 -108\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "1412 105 \n",
      " 816 108\n",
      "321 -195\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "171 133 \n",
      " 1281 195\n",
      "-657 -309\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "194 221 \n",
      " 657 309\n",
      "258 -375\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "132 85 \n",
      " 1218 375\n",
      "216 -483\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "979 216 \n",
      " 1176 483\n",
      "450 -228\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "117 272 \n",
      " 1410 228\n",
      "378 201\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "191 229 \n",
      " 1338 741\n",
      "48 -177\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "1012 265 \n",
      " 1008 177\n",
      "393 -126\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "160 38 \n",
      " 1353 126\n",
      "201 -414\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "8 333 \n",
      " 1161 414\n",
      "132 -474\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "1047 432 \n",
      " 1092 474\n",
      "264 -192\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "1045 228 \n",
      " 1224 192\n",
      "192 -321\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "1154 279 \n",
      " 1152 321\n",
      "144 -432\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "196 209 \n",
      " 1104 432\n",
      "102 -210\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "984 145 \n",
      " 1062 210\n",
      "285 192\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "1035 225 \n",
      " 1245 732\n",
      "-705 -447\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "357 213 \n",
      " 705 447\n",
      "180 -489\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "1123 365 \n",
      " 1140 489\n",
      "-747 -393\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "139 197 \n",
      " 747 393\n",
      "279 -474\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step\n",
      "1105 365 \n",
      " 1239 474\n",
      "-393 -267\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step\n",
      "971 89 \n",
      " 393 267\n",
      "339 -300\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "312 201 \n",
      " 1299 300\n",
      "87 48\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "556 73 \n",
      " 1047 588\n",
      "333 -144\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "1344 76 \n",
      " 1293 144\n",
      "216 -345\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "1043 279 \n",
      " 1176 345\n",
      "-657 -399\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "243 245 \n",
      " 657 399\n",
      "51 -351\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "37 268 \n",
      " 1011 351\n",
      "42 -159\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "965 272 \n",
      " 1002 159\n",
      "24 12\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "273 136 \n",
      " 984 552\n",
      "168 -102\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "323 179 \n",
      " 1128 102\n",
      "240 -330\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "119 234 \n",
      " 1200 330\n",
      "-288 -201\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "169 17 \n",
      " 288 201\n",
      "726 -366\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "184 108 \n",
      " 1686 366\n",
      "102 -138\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "48 168 \n",
      " 1062 138\n",
      "240 -483\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "1120 480 \n",
      " 1200 483\n",
      "186 -201\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "1012 279 \n",
      " 1146 201\n",
      "48 -222\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "68 143 \n",
      " 1008 222\n",
      "465 -288\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "35 18 \n",
      " 1425 288\n",
      "-186 -267\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "90 52 \n",
      " 186 267\n",
      "165 -312\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "974 198 \n",
      " 1125 312\n",
      "123 45\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "1121 575 \n",
      " 1083 585\n",
      "108 -216\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "1016 154 \n",
      " 1068 216\n",
      "105 -204\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step\n",
      "1057 218 \n",
      " 1065 204\n",
      "147 -282\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "1219 273 \n",
      " 1107 282\n",
      "690 -234\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step\n",
      "131 19 \n",
      " 1650 234\n",
      "192 -312\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "1224 131 \n",
      " 1152 312\n",
      "-675 -471\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "16 225 \n",
      " 675 471\n",
      "96 66\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "74 311 \n",
      " 1056 606\n",
      "198 -462\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "990 277 \n",
      " 1158 462\n",
      "156 -225\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "1031 211 \n",
      " 1116 225\n",
      "105 -144\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "974 218 \n",
      " 1065 144\n",
      "-504 -501\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "9 10 \n",
      " 504 501\n",
      "219 -195\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "1059 183 \n",
      " 1179 195\n",
      "126 -315\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "188 308 \n",
      " 1086 315\n",
      "-570 -384\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "164 682 \n",
      " 570 384\n",
      "246 -474\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "1107 301 \n",
      " 1206 474\n",
      "117 27\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "234 176 \n",
      " 1077 567\n",
      "297 168\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "1017 163 \n",
      " 1257 708\n",
      "-174 -156\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "437 168 \n",
      " 174 156\n",
      "159 -177\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "1025 174 \n",
      " 1119 177\n",
      "210 -414\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "1041 198 \n",
      " 1170 414\n",
      "-642 -165\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "1219 387 \n",
      " 642 165\n",
      "147 -417\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "219 190 \n",
      " 1107 417\n",
      "369 -375\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "1039 72 \n",
      " 1329 375\n",
      "219 -513\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "1032 376 \n",
      " 1179 513\n",
      "-786 -201\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step\n",
      "189 168 \n",
      " 786 201\n",
      "225 102\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "94 238 \n",
      " 1185 642\n",
      "90 -117\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "989 228 \n",
      " 1050 117\n"
     ]
    }
   ],
   "source": [
    "model_rap = tf.keras.models.load_model('mouse_attack_fhd_normalized.h5')\n",
    "\n",
    "\n",
    "for n in range(len(y_val)):\n",
    "    x_real, y_real = int(y_val[n][0]), int(y_val[n][1])\n",
    "    print(x_real, y_real)\n",
    "    img = np.asarray(X_val[n])\n",
    "    if x_real < 0:\n",
    "        x_real = -x_real \n",
    "    else:\n",
    "        x_real = x_real + 960\n",
    "    \n",
    "    if y_real < 0:\n",
    "        y_real = -y_real\n",
    "    else:\n",
    "        y_real = y_real + 540\n",
    "        \n",
    "    \n",
    "    tbp = np.expand_dims(img, axis=0)\n",
    "    img = cv2.resize(img,(1920,1080))\n",
    "    predictions = model_rap.predict(tbp)\n",
    "    \n",
    "    x, y = int(predictions[0][0]), int(predictions[0][1])\n",
    "    if x < 0:\n",
    "        x = -x \n",
    "    else:\n",
    "        x = x + 960\n",
    "    \n",
    "    if y < 0:\n",
    "        y = -y\n",
    "    else:\n",
    "        y = y + 540\n",
    "        \n",
    "    print(x, y, \"\\n\",x_real, y_real)\n",
    "    cv2.circle(img, (x,y), 10, (0,0,255), -1)\n",
    "    cv2.circle(img, (x_real, y_real), 10, (255,0,0), -1)\n",
    "    cv2.imshow('ss', img)\n",
    "    cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyWindow('ss')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T22:03:38.405381Z",
     "start_time": "2024-06-26T22:02:30.058169Z"
    }
   },
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 2s/step - accuracy: 0.7854 - loss: 0.5956 - val_accuracy: 0.7400 - val_loss: 0.7340\n",
      "Epoch 2/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8160 - loss: 0.5927 - val_accuracy: 0.7000 - val_loss: 0.7350\n",
      "Epoch 3/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7564 - loss: 0.6643 - val_accuracy: 0.6900 - val_loss: 0.7348\n",
      "Epoch 4/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7663 - loss: 0.5880 - val_accuracy: 0.7200 - val_loss: 0.7174\n",
      "Epoch 5/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7939 - loss: 0.5774 - val_accuracy: 0.7500 - val_loss: 0.6913\n",
      "Epoch 6/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7758 - loss: 0.5911 - val_accuracy: 0.7700 - val_loss: 0.6796\n",
      "Epoch 7/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8515 - loss: 0.5431 - val_accuracy: 0.7200 - val_loss: 0.6956\n",
      "Epoch 8/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8156 - loss: 0.5335 - val_accuracy: 0.7600 - val_loss: 0.6792\n",
      "Epoch 9/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8056 - loss: 0.5467 - val_accuracy: 0.7200 - val_loss: 0.7013\n",
      "Epoch 10/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8051 - loss: 0.5673 - val_accuracy: 0.7100 - val_loss: 0.7006\n",
      "Epoch 11/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8292 - loss: 0.5415 - val_accuracy: 0.7500 - val_loss: 0.6691\n",
      "Epoch 12/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 2s/step - accuracy: 0.8229 - loss: 0.5179 - val_accuracy: 0.7200 - val_loss: 0.6990\n",
      "Epoch 13/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8009 - loss: 0.5460 - val_accuracy: 0.6900 - val_loss: 0.6973\n",
      "Epoch 14/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7653 - loss: 0.5336 - val_accuracy: 0.7700 - val_loss: 0.6708\n",
      "Epoch 15/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8264 - loss: 0.5135 - val_accuracy: 0.7700 - val_loss: 0.6614\n",
      "Epoch 16/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8060 - loss: 0.5054 - val_accuracy: 0.7600 - val_loss: 0.6824\n",
      "Epoch 17/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8354 - loss: 0.5115 - val_accuracy: 0.7600 - val_loss: 0.6536\n",
      "Epoch 18/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8681 - loss: 0.4536 - val_accuracy: 0.7600 - val_loss: 0.6766\n",
      "Epoch 19/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 2s/step - accuracy: 0.8218 - loss: 0.5394 - val_accuracy: 0.7100 - val_loss: 0.6732\n",
      "Epoch 20/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8353 - loss: 0.4712 - val_accuracy: 0.7700 - val_loss: 0.6523\n",
      "Epoch 21/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8529 - loss: 0.4668 - val_accuracy: 0.7100 - val_loss: 0.6923\n",
      "Epoch 22/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8522 - loss: 0.4319 - val_accuracy: 0.7700 - val_loss: 0.6449\n",
      "Epoch 23/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8681 - loss: 0.4631 - val_accuracy: 0.7300 - val_loss: 0.6725\n",
      "Epoch 24/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8439 - loss: 0.4439 - val_accuracy: 0.7700 - val_loss: 0.6619\n",
      "Epoch 25/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8564 - loss: 0.4528 - val_accuracy: 0.7600 - val_loss: 0.6535\n",
      "Epoch 26/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8554 - loss: 0.4464 - val_accuracy: 0.7400 - val_loss: 0.6673\n",
      "Epoch 27/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8581 - loss: 0.4503 - val_accuracy: 0.7000 - val_loss: 0.6875\n",
      "Epoch 28/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8117 - loss: 0.4651 - val_accuracy: 0.7500 - val_loss: 0.6522\n",
      "Epoch 29/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8064 - loss: 0.5049 - val_accuracy: 0.7600 - val_loss: 0.6364\n",
      "Epoch 30/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8587 - loss: 0.4138 - val_accuracy: 0.7600 - val_loss: 0.6359\n",
      "Epoch 31/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8649 - loss: 0.4344 - val_accuracy: 0.7200 - val_loss: 0.6650\n",
      "Epoch 32/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8220 - loss: 0.4698 - val_accuracy: 0.7600 - val_loss: 0.6422\n",
      "Epoch 33/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8664 - loss: 0.4280 - val_accuracy: 0.7500 - val_loss: 0.6419\n",
      "Epoch 34/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8537 - loss: 0.4586 - val_accuracy: 0.7300 - val_loss: 0.6673\n",
      "Epoch 35/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8153 - loss: 0.4400 - val_accuracy: 0.7600 - val_loss: 0.6362\n",
      "Epoch 36/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8621 - loss: 0.4108 - val_accuracy: 0.7400 - val_loss: 0.6569\n",
      "Epoch 37/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.9073 - loss: 0.4215 - val_accuracy: 0.7400 - val_loss: 0.6347\n",
      "Epoch 38/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.9043 - loss: 0.3788 - val_accuracy: 0.7500 - val_loss: 0.6797\n",
      "Epoch 39/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8784 - loss: 0.3959 - val_accuracy: 0.7500 - val_loss: 0.6327\n",
      "Epoch 40/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8892 - loss: 0.3638 - val_accuracy: 0.7300 - val_loss: 0.6599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_rap = tf.keras.models.load_model('my_mobilenet_model.h5')\n",
    "model_rap.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_rap.fit(X_train, y_train, epochs=40, validation_data=(X_val, y_val))\n",
    "model_rap.save('class_2.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T23:52:56.002640Z",
     "start_time": "2024-06-26T23:34:37.673693600Z"
    }
   },
   "execution_count": 28
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
