{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:35:49.757379Z",
     "start_time": "2024-06-27T02:35:39.047489800Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_input():\n",
    "    X = []\n",
    "    y = []\n",
    "    df = pd.read_csv(\"classification_data/attack_img/attack_data.csv\")\n",
    "    shuffled_df = df.sample(len(df))\n",
    "\n",
    "    print(shuffled_df.head)\n",
    "    s = 0\n",
    "    for entry in shuffled_df.values:\n",
    "        s += 1\n",
    "        # print(s)\n",
    "        entry_img = cv2.imread(f\"classification_data/attack_img/{entry[0]}\")\n",
    "\n",
    "        prepared_y = np.delete(entry,0)\n",
    "\n",
    "        X.append(entry_img)\n",
    "        y.append(prepared_y)\n",
    "\n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).astype(np.float32)\n",
    "    return X, y\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:36:19.884846400Z",
     "start_time": "2024-06-27T02:36:19.877869300Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compile_model():\n",
    "    image_width, image_height, channels = 640, 360, 3  # Assuming RGB images\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(image_height, image_width, channels)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = compile_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:27:32.382552800Z",
     "start_time": "2024-06-27T02:27:31.697497Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:27:32.523764400Z",
     "start_time": "2024-06-27T02:27:32.501265900Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            filename    x    y\n",
      "267  attack_267.jpg  346   45\n",
      "8      attack_8.jpg  382  104\n",
      "265  attack_265.jpg  408   64\n",
      "201  attack_201.jpg  562  122\n",
      "61    attack_61.jpg  378   86\n",
      "..              ...  ...  ...\n",
      "79    attack_79.jpg  345   54\n",
      "184  attack_184.jpg  415  244\n",
      "270  attack_270.jpg  318  197\n",
      "217  attack_217.jpg  375   84\n",
      "7      attack_7.jpg  383   39\n",
      "\n",
      "[325 rows x 3 columns]>\n",
      "(260, 360, 640, 3) (260, 2)\n"
     ]
    }
   ],
   "source": [
    "X, y = create_input()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:36:23.861912800Z",
     "start_time": "2024-06-27T02:36:21.326156100Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 1s/step - accuracy: 0.8148 - loss: 28142030.0000 - val_accuracy: 0.0000e+00 - val_loss: 326316.0312\n",
      "Epoch 2/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - accuracy: 0.4173 - loss: 274543.5000 - val_accuracy: 1.0000 - val_loss: 3953.7593\n",
      "Epoch 3/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - accuracy: 0.9303 - loss: 70538.8828 - val_accuracy: 1.0000 - val_loss: 33430.2773\n",
      "Epoch 4/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - accuracy: 0.9842 - loss: 39565.0156 - val_accuracy: 0.0000e+00 - val_loss: 28981.1328\n",
      "Epoch 5/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1s/step - accuracy: 0.7069 - loss: 21217.7676 - val_accuracy: 1.0000 - val_loss: 11851.2568\n",
      "Epoch 6/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - accuracy: 0.9979 - loss: 7824.6597 - val_accuracy: 1.0000 - val_loss: 3741.9453\n",
      "Epoch 7/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - accuracy: 0.9954 - loss: 4822.7090 - val_accuracy: 1.0000 - val_loss: 3201.0923\n",
      "Epoch 8/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 1s/step - accuracy: 0.9965 - loss: 3578.2771 - val_accuracy: 1.0000 - val_loss: 3488.4241\n",
      "Epoch 9/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1s/step - accuracy: 0.9988 - loss: 2685.8257 - val_accuracy: 1.0000 - val_loss: 2797.7810\n",
      "Epoch 10/10\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 1s/step - accuracy: 0.9988 - loss: 2668.7959 - val_accuracy: 1.0000 - val_loss: 2650.1450\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x25de57d3c20>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:31:33.417748200Z",
     "start_time": "2024-06-27T02:29:51.737528800Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2679.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy:', accuracy)\n",
    "\n",
    "model.save('mouse_attack.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:31:52.271273300Z",
     "start_time": "2024-06-27T02:31:49.475208700Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373 104\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 134ms/step\n",
      "347 130 \n",
      " 373 104\n",
      "365 101\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step\n",
      "323 108 \n",
      " 365 101\n",
      "352 165\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "396 184 \n",
      " 352 165\n",
      "297 212\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step\n",
      "399 154 \n",
      " 297 212\n",
      "401 138\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "383 144 \n",
      " 401 138\n"
     ]
    }
   ],
   "source": [
    "model_rap = tf.keras.models.load_model('mouse_attack.h5')\n",
    "\n",
    "\n",
    "for n in range(5):\n",
    "    x_real, y_real = int(y_val[n][0]), int(y_val[n][1])\n",
    "    print(x_real, y_real)\n",
    "    img = np.asarray(X_val[n])\n",
    "    \n",
    "    tbp = np.expand_dims(img, axis=0)\n",
    "    predictions = model_rap.predict(tbp)\n",
    "    x, y = int(predictions[0][0]), int(predictions[0][1]),\n",
    "    print(x, y, \"\\n\",x_real, y_real)\n",
    "    cv2.circle(img, (x,y), 10, (0,0,255), -1)\n",
    "    cv2.circle(img, (x_real, y_real), 10, (255,0,0), -1)\n",
    "    cv2.imshow('ss', img)\n",
    "    cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyWindow('ss')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:40:24.526464900Z",
     "start_time": "2024-06-27T02:40:07.326401700Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 2s/step - accuracy: 0.7854 - loss: 0.5956 - val_accuracy: 0.7400 - val_loss: 0.7340\n",
      "Epoch 2/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8160 - loss: 0.5927 - val_accuracy: 0.7000 - val_loss: 0.7350\n",
      "Epoch 3/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7564 - loss: 0.6643 - val_accuracy: 0.6900 - val_loss: 0.7348\n",
      "Epoch 4/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7663 - loss: 0.5880 - val_accuracy: 0.7200 - val_loss: 0.7174\n",
      "Epoch 5/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7939 - loss: 0.5774 - val_accuracy: 0.7500 - val_loss: 0.6913\n",
      "Epoch 6/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7758 - loss: 0.5911 - val_accuracy: 0.7700 - val_loss: 0.6796\n",
      "Epoch 7/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8515 - loss: 0.5431 - val_accuracy: 0.7200 - val_loss: 0.6956\n",
      "Epoch 8/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8156 - loss: 0.5335 - val_accuracy: 0.7600 - val_loss: 0.6792\n",
      "Epoch 9/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8056 - loss: 0.5467 - val_accuracy: 0.7200 - val_loss: 0.7013\n",
      "Epoch 10/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8051 - loss: 0.5673 - val_accuracy: 0.7100 - val_loss: 0.7006\n",
      "Epoch 11/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8292 - loss: 0.5415 - val_accuracy: 0.7500 - val_loss: 0.6691\n",
      "Epoch 12/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 2s/step - accuracy: 0.8229 - loss: 0.5179 - val_accuracy: 0.7200 - val_loss: 0.6990\n",
      "Epoch 13/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8009 - loss: 0.5460 - val_accuracy: 0.6900 - val_loss: 0.6973\n",
      "Epoch 14/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.7653 - loss: 0.5336 - val_accuracy: 0.7700 - val_loss: 0.6708\n",
      "Epoch 15/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8264 - loss: 0.5135 - val_accuracy: 0.7700 - val_loss: 0.6614\n",
      "Epoch 16/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8060 - loss: 0.5054 - val_accuracy: 0.7600 - val_loss: 0.6824\n",
      "Epoch 17/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 2s/step - accuracy: 0.8354 - loss: 0.5115 - val_accuracy: 0.7600 - val_loss: 0.6536\n",
      "Epoch 18/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8681 - loss: 0.4536 - val_accuracy: 0.7600 - val_loss: 0.6766\n",
      "Epoch 19/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 2s/step - accuracy: 0.8218 - loss: 0.5394 - val_accuracy: 0.7100 - val_loss: 0.6732\n",
      "Epoch 20/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8353 - loss: 0.4712 - val_accuracy: 0.7700 - val_loss: 0.6523\n",
      "Epoch 21/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8529 - loss: 0.4668 - val_accuracy: 0.7100 - val_loss: 0.6923\n",
      "Epoch 22/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8522 - loss: 0.4319 - val_accuracy: 0.7700 - val_loss: 0.6449\n",
      "Epoch 23/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8681 - loss: 0.4631 - val_accuracy: 0.7300 - val_loss: 0.6725\n",
      "Epoch 24/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8439 - loss: 0.4439 - val_accuracy: 0.7700 - val_loss: 0.6619\n",
      "Epoch 25/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8564 - loss: 0.4528 - val_accuracy: 0.7600 - val_loss: 0.6535\n",
      "Epoch 26/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8554 - loss: 0.4464 - val_accuracy: 0.7400 - val_loss: 0.6673\n",
      "Epoch 27/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8581 - loss: 0.4503 - val_accuracy: 0.7000 - val_loss: 0.6875\n",
      "Epoch 28/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8117 - loss: 0.4651 - val_accuracy: 0.7500 - val_loss: 0.6522\n",
      "Epoch 29/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8064 - loss: 0.5049 - val_accuracy: 0.7600 - val_loss: 0.6364\n",
      "Epoch 30/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8587 - loss: 0.4138 - val_accuracy: 0.7600 - val_loss: 0.6359\n",
      "Epoch 31/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8649 - loss: 0.4344 - val_accuracy: 0.7200 - val_loss: 0.6650\n",
      "Epoch 32/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8220 - loss: 0.4698 - val_accuracy: 0.7600 - val_loss: 0.6422\n",
      "Epoch 33/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8664 - loss: 0.4280 - val_accuracy: 0.7500 - val_loss: 0.6419\n",
      "Epoch 34/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8537 - loss: 0.4586 - val_accuracy: 0.7300 - val_loss: 0.6673\n",
      "Epoch 35/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8153 - loss: 0.4400 - val_accuracy: 0.7600 - val_loss: 0.6362\n",
      "Epoch 36/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8621 - loss: 0.4108 - val_accuracy: 0.7400 - val_loss: 0.6569\n",
      "Epoch 37/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.9073 - loss: 0.4215 - val_accuracy: 0.7400 - val_loss: 0.6347\n",
      "Epoch 38/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.9043 - loss: 0.3788 - val_accuracy: 0.7500 - val_loss: 0.6797\n",
      "Epoch 39/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8784 - loss: 0.3959 - val_accuracy: 0.7500 - val_loss: 0.6327\n",
      "Epoch 40/40\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 2s/step - accuracy: 0.8892 - loss: 0.3638 - val_accuracy: 0.7300 - val_loss: 0.6599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_rap = tf.keras.models.load_model('my_mobilenet_model.h5')\n",
    "model_rap.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_rap.fit(X_train, y_train, epochs=40, validation_data=(X_val, y_val))\n",
    "model_rap.save('class_2.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T23:52:56.002640Z",
     "start_time": "2024-06-26T23:34:37.673693600Z"
    }
   },
   "execution_count": 28
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
