{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T16:29:45.072526600Z",
     "start_time": "2024-07-03T16:29:45.030118600Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MobileNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m input_shape \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m360\u001B[39m, \u001B[38;5;241m640\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Load MobileNet, excluding the final classification layer\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m mobilenet \u001B[38;5;241m=\u001B[39m \u001B[43mMobileNet\u001B[49m(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m'\u001B[39m, include_top\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, input_shape\u001B[38;5;241m=\u001B[39minput_shape)\n\u001B[0;32m      8\u001B[0m x \u001B[38;5;241m=\u001B[39m GlobalAveragePooling2D()(mobilenet\u001B[38;5;241m.\u001B[39moutput)\n\u001B[0;32m     10\u001B[0m predictions \u001B[38;5;241m=\u001B[39m Dense(\u001B[38;5;241m2\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmoid\u001B[39m\u001B[38;5;124m'\u001B[39m)(x)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'MobileNet' is not defined"
     ]
    }
   ],
   "source": [
    "# Define input shape based on your image size (here, 640x360)\n",
    "input_shape = (360, 640, 3)\n",
    "\n",
    "# Load MobileNet, excluding the final classification layer\n",
    "mobilenet = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(mobilenet.output)\n",
    "\n",
    "predictions = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=mobilenet.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T16:29:46.263011800Z",
     "start_time": "2024-07-03T16:29:46.187695700Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "###default\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "folder_path = 'classification_data/'\n",
    "\n",
    "for folder_name in ['attack_img', 'explore_img']: #, 'loot_img', 'getaway_img']:\n",
    "    folder_full_path = os.path.join(folder_path + folder_name)\n",
    "    \n",
    "    class_label = {\n",
    "      'attack_img': [1,0],\n",
    "      'explore_img': [0,1],\n",
    "      # 'loot_img': [0,0,1,0],\n",
    "      # 'getaway_img': [0,0,0,1]\n",
    "    }[folder_name]\n",
    "    \n",
    "    for filename in os.listdir(folder_full_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img = cv2.imread(os.path.join(folder_full_path, filename))\n",
    "\n",
    "            X.append(img)\n",
    "            \n",
    "            y.append(class_label)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T16:30:36.510447Z",
     "start_time": "2024-07-03T16:29:58.804535400Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:30:42.071250600Z",
     "start_time": "2024-07-03T16:30:36.514435900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## aug\n",
    "folder_path = 'augmented_data/'\n",
    "\n",
    "for folder_name in ['attack_img', 'explore_img']: #, 'loot_img', 'getaway_img']:\n",
    "    folder_full_path = os.path.join(folder_path + folder_name)\n",
    "    \n",
    "    class_label = {\n",
    "      'attack_img': [1,0],\n",
    "      'explore_img': [0,1],\n",
    "      # 'loot_img': [0,0,1,0],\n",
    "      # 'getaway_img': [0,0,0,1]\n",
    "    }[folder_name]\n",
    "    \n",
    "    for filename in os.listdir(folder_full_path):\n",
    "        if filename.endswith(\".jpg\") :\n",
    "            img = cv2.imread(os.path.join(folder_full_path, filename))\n",
    "        \n",
    "            # Append image to X and label to y\n",
    "            X.append(img)\n",
    "            \n",
    "            \n",
    "            y.append(class_label)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:30:42.211032900Z",
     "start_time": "2024-07-03T16:30:42.074243500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for n in range(len(X)):\n",
    "    if n % 10 == 0:\n",
    "        X[n] = cv2.cvtColor(X[n], cv2.COLOR_BGR2HSV)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T16:30:46.188853300Z",
     "start_time": "2024-07-03T16:30:42.204053900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4987, 360, 640, 3) (4987, 2)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:31:31.987471100Z",
     "start_time": "2024-07-03T16:31:31.686843400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_rap = tf.keras.models.load_model('classificator_newgen_augment_gpu.h5', compile = False)\n",
    "model_rap.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_rap.fit(X_train, y_train, epochs=2, validation_data=(X_val, y_val))\n",
    "model_rap.save('classificator_newgen_augment2.h5')"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'DepthwiseConv2D' using config={'name': 'conv_dw_1', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:234\u001B[0m, in \u001B[0;36mOperation.from_config\u001B[1;34m(cls, config)\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\depthwise_conv2d.py:120\u001B[0m, in \u001B[0;36mDepthwiseConv2D.__init__\u001B[1;34m(self, kernel_size, strides, padding, depth_multiplier, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, **kwargs)\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    103\u001B[0m     kernel_size,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    119\u001B[0m ):\n\u001B[1;32m--> 120\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdepth_multiplier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepth_multiplier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdilation_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdilation_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m        \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdepthwise_initializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepthwise_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    131\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_initializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdepthwise_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepthwise_regularizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias_regularizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mactivity_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactivity_regularizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdepthwise_constraint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepthwise_constraint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_constraint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias_constraint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_depthwise_conv.py:106\u001B[0m, in \u001B[0;36mBaseDepthwiseConv.__init__\u001B[1;34m(self, rank, depth_multiplier, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, trainable, name, **kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     86\u001B[0m     rank,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    105\u001B[0m ):\n\u001B[1;32m--> 106\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrainable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    109\u001B[0m \u001B[43m        \u001B[49m\u001B[43mactivity_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mregularizers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivity_regularizer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrank \u001B[38;5;241m=\u001B[39m rank\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:266\u001B[0m, in \u001B[0;36mLayer.__init__\u001B[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001B[0m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs:\n\u001B[1;32m--> 266\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    267\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized keyword arguments \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    268\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassed to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwargs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    269\u001B[0m     )\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# Will be determined in `build_wrapper`\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model_rap \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclassificator_newgen_augment_gpu.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m model_rap\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      3\u001B[0m               loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      4\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      6\u001B[0m model_rap\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, validation_data\u001B[38;5;241m=\u001B[39m(X_val, y_val))\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:189\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m    183\u001B[0m         filepath,\n\u001B[0;32m    184\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[0;32m    185\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[0;32m    186\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[0;32m    187\u001B[0m     )\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(filepath)\u001B[38;5;241m.\u001B[39mendswith((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.hdf5\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[1;32m--> 189\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_h5_format\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model_from_hdf5\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\n\u001B[0;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(filepath)\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    193\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    194\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile not found: filepath=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    195\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease ensure the file is an accessible `.keras` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    196\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzip file.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    197\u001B[0m     )\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:133\u001B[0m, in \u001B[0;36mload_model_from_hdf5\u001B[1;34m(filepath, custom_objects, compile)\u001B[0m\n\u001B[0;32m    130\u001B[0m model_config \u001B[38;5;241m=\u001B[39m json_utils\u001B[38;5;241m.\u001B[39mdecode(model_config)\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m saving_options\u001B[38;5;241m.\u001B[39mkeras_option_scope(use_legacy_config\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 133\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43msaving_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_from_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# set weights\u001B[39;00m\n\u001B[0;32m    138\u001B[0m     load_weights_from_hdf5_group(f[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_weights\u001B[39m\u001B[38;5;124m\"\u001B[39m], model)\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:85\u001B[0m, in \u001B[0;36mmodel_from_config\u001B[1;34m(config, custom_objects)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# Replace keras refs with keras\u001B[39;00m\n\u001B[0;32m     83\u001B[0m config \u001B[38;5;241m=\u001B[39m _find_replace_nested_dict(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mserialization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODULE_OBJECTS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mALL_OBJECTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlayer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:495\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[0;32m    490\u001B[0m cls_config \u001B[38;5;241m=\u001B[39m _find_replace_nested_dict(\n\u001B[0;32m    491\u001B[0m     cls_config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    492\u001B[0m )\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustom_objects\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m arg_spec\u001B[38;5;241m.\u001B[39margs:\n\u001B[1;32m--> 495\u001B[0m     deserialized_obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcls_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mobject_registration\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGLOBAL_CUSTOM_OBJECTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    503\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m object_registration\u001B[38;5;241m.\u001B[39mCustomObjectScope(custom_objects):\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\models\\model.py:521\u001B[0m, in \u001B[0;36mModel.from_config\u001B[1;34m(cls, config, custom_objects)\u001B[0m\n\u001B[0;32m    516\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_functional_config \u001B[38;5;129;01mand\u001B[39;00m revivable_as_functional:\n\u001B[0;32m    517\u001B[0m     \u001B[38;5;66;03m# Revive Functional model\u001B[39;00m\n\u001B[0;32m    518\u001B[0m     \u001B[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001B[39;00m\n\u001B[0;32m    519\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functional_from_config\n\u001B[1;32m--> 521\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunctional_from_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[38;5;66;03m# Either the model has a custom __init__, or the config\u001B[39;00m\n\u001B[0;32m    526\u001B[0m \u001B[38;5;66;03m# does not contain all the information necessary to\u001B[39;00m\n\u001B[0;32m    527\u001B[0m \u001B[38;5;66;03m# revive a Functional model. This happens when the user creates\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    530\u001B[0m \u001B[38;5;66;03m# In this case, we fall back to provide all config into the\u001B[39;00m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;66;03m# constructor of the class.\u001B[39;00m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\models\\functional.py:477\u001B[0m, in \u001B[0;36mfunctional_from_config\u001B[1;34m(cls, config, custom_objects)\u001B[0m\n\u001B[0;32m    475\u001B[0m \u001B[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001B[39;00m\n\u001B[0;32m    476\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer_data \u001B[38;5;129;01min\u001B[39;00m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayers\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 477\u001B[0m     \u001B[43mprocess_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayer_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[38;5;66;03m# Then we process nodes in order of layer depth.\u001B[39;00m\n\u001B[0;32m    480\u001B[0m \u001B[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001B[39;00m\n\u001B[0;32m    481\u001B[0m \u001B[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001B[39;00m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;66;03m# is repeated until all nodes are processed.\u001B[39;00m\n\u001B[0;32m    483\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m unprocessed_nodes:\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\models\\functional.py:457\u001B[0m, in \u001B[0;36mfunctional_from_config.<locals>.process_layer\u001B[1;34m(layer_data)\u001B[0m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;66;03m# Instantiate layer.\u001B[39;00m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m layer_data:\n\u001B[0;32m    455\u001B[0m     \u001B[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001B[39;00m\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;66;03m# used for H5 and SavedModel formats\u001B[39;00m\n\u001B[1;32m--> 457\u001B[0m     layer \u001B[38;5;241m=\u001B[39m \u001B[43msaving_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_from_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    461\u001B[0m     layer \u001B[38;5;241m=\u001B[39m serialization_lib\u001B[38;5;241m.\u001B[39mdeserialize_keras_object(\n\u001B[0;32m    462\u001B[0m         layer_data, custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects\n\u001B[0;32m    463\u001B[0m     )\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:85\u001B[0m, in \u001B[0;36mmodel_from_config\u001B[1;34m(config, custom_objects)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# Replace keras refs with keras\u001B[39;00m\n\u001B[0;32m     83\u001B[0m config \u001B[38;5;241m=\u001B[39m _find_replace_nested_dict(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mserialization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODULE_OBJECTS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mALL_OBJECTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlayer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:504\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[0;32m    502\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    503\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m object_registration\u001B[38;5;241m.\u001B[39mCustomObjectScope(custom_objects):\n\u001B[1;32m--> 504\u001B[0m             deserialized_obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcls_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     \u001B[38;5;66;03m# Then `cls` may be a function returning a class.\u001B[39;00m\n\u001B[0;32m    507\u001B[0m     \u001B[38;5;66;03m# in this case by convention `config` holds\u001B[39;00m\n\u001B[0;32m    508\u001B[0m     \u001B[38;5;66;03m# the kwargs of the function.\u001B[39;00m\n\u001B[0;32m    509\u001B[0m     custom_objects \u001B[38;5;241m=\u001B[39m custom_objects \u001B[38;5;129;01mor\u001B[39;00m {}\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:236\u001B[0m, in \u001B[0;36mOperation.from_config\u001B[1;34m(cls, config)\u001B[0m\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig)\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError when deserializing class \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m using \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfig=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mException encountered: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    239\u001B[0m     )\n",
      "\u001B[1;31mTypeError\u001B[0m: Error when deserializing class 'DepthwiseConv2D' using config={'name': 'conv_dw_1', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(X_train, y_train, epochs=2, validation_data=(X_val, y_val))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T17:54:30.776069Z",
     "start_time": "2024-07-01T17:54:30.175008Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, validation_data\u001B[38;5;241m=\u001B[39m(X_val, y_val))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('classificator_newgen_augment.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T13:24:25.226110700Z",
     "start_time": "2024-07-01T13:24:24.977835100Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "model_rap = tf.keras.models.load_model('classificator_newgen_augment_gpu.h5', compile = False)\n",
    "model_rap.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "for n in range(20):\n",
    "    y_real = y_val[n]\n",
    "    tbp = np.asarray(X_val[n])\n",
    "    cv2.imshow('ss', tbp)\n",
    "    tbp = np.expand_dims(tbp, axis=0)\n",
    "    predictions = model_rap.predict(tbp)\n",
    "    print(predictions, \"\\n\", y_real)\n",
    "\n",
    "    cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyWindow('ss')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T18:05:55.075284Z",
     "start_time": "2024-07-01T18:04:17.160925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1s/step\n",
      "[[0.73107713 0.1901052 ]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step\n",
      "[[0.5325008  0.15768382]] \n",
      " [0 1]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 110ms/step\n",
      "[[0.04249566 0.6500043 ]] \n",
      " [0 1]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 100ms/step\n",
      "[[0.56193626 0.2174966 ]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step\n",
      "[[0.3195008  0.41426015]] \n",
      " [0 1]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step\n",
      "[[0.8333505  0.20539805]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 104ms/step\n",
      "[[0.32585075 0.49869403]] \n",
      " [0 1]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 100ms/step\n",
      "[[0.6378327  0.32990855]] \n",
      " [0 1]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 102ms/step\n",
      "[[0.6095849 0.5014807]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 101ms/step\n",
      "[[0.5882802  0.29877174]] \n",
      " [0 1]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 102ms/step\n",
      "[[0.848505   0.10922904]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step\n",
      "[[0.49784544 0.38235372]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 101ms/step\n",
      "[[0.3201364  0.51327956]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 120ms/step\n",
      "[[0.87436616 0.06132353]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step\n",
      "[[0.78483725 0.11527899]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 106ms/step\n",
      "[[0.81132615 0.0695824 ]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step\n",
      "[[0.68450177 0.12978286]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 101ms/step\n",
      "[[0.9047812  0.06247845]] \n",
      " [1 0]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 101ms/step\n",
      "[[0.41519058 0.3576645 ]] \n",
      " [0 1]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step\n",
      "[[0.38954076 0.38664094]] \n",
      " [0 1]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "augmented data fragment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'DepthwiseConv2D' using config={'name': 'conv_dw_1', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:234\u001B[0m, in \u001B[0;36mOperation.from_config\u001B[1;34m(cls, config)\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\depthwise_conv2d.py:120\u001B[0m, in \u001B[0;36mDepthwiseConv2D.__init__\u001B[1;34m(self, kernel_size, strides, padding, depth_multiplier, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, **kwargs)\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    103\u001B[0m     kernel_size,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    119\u001B[0m ):\n\u001B[1;32m--> 120\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdepth_multiplier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepth_multiplier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdilation_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdilation_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m        \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdepthwise_initializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepthwise_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    131\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_initializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdepthwise_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepthwise_regularizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias_regularizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mactivity_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactivity_regularizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdepthwise_constraint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepthwise_constraint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_constraint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias_constraint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_depthwise_conv.py:106\u001B[0m, in \u001B[0;36mBaseDepthwiseConv.__init__\u001B[1;34m(self, rank, depth_multiplier, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, trainable, name, **kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     86\u001B[0m     rank,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    105\u001B[0m ):\n\u001B[1;32m--> 106\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrainable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    109\u001B[0m \u001B[43m        \u001B[49m\u001B[43mactivity_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mregularizers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivity_regularizer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrank \u001B[38;5;241m=\u001B[39m rank\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:266\u001B[0m, in \u001B[0;36mLayer.__init__\u001B[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001B[0m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs:\n\u001B[1;32m--> 266\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    267\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized keyword arguments \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    268\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassed to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwargs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    269\u001B[0m     )\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# Will be determined in `build_wrapper`\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model_rap \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclassificator_newgen_augment_gpu.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m model_rap\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      3\u001B[0m               loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      4\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      6\u001B[0m model_rap\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, validation_data\u001B[38;5;241m=\u001B[39m(X_val, y_val), batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m)\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:189\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m    183\u001B[0m         filepath,\n\u001B[0;32m    184\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[0;32m    185\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[0;32m    186\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[0;32m    187\u001B[0m     )\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(filepath)\u001B[38;5;241m.\u001B[39mendswith((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.hdf5\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[1;32m--> 189\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_h5_format\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model_from_hdf5\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\n\u001B[0;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(filepath)\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    193\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    194\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile not found: filepath=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    195\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease ensure the file is an accessible `.keras` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    196\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzip file.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    197\u001B[0m     )\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:133\u001B[0m, in \u001B[0;36mload_model_from_hdf5\u001B[1;34m(filepath, custom_objects, compile)\u001B[0m\n\u001B[0;32m    130\u001B[0m model_config \u001B[38;5;241m=\u001B[39m json_utils\u001B[38;5;241m.\u001B[39mdecode(model_config)\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m saving_options\u001B[38;5;241m.\u001B[39mkeras_option_scope(use_legacy_config\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 133\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43msaving_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_from_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# set weights\u001B[39;00m\n\u001B[0;32m    138\u001B[0m     load_weights_from_hdf5_group(f[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_weights\u001B[39m\u001B[38;5;124m\"\u001B[39m], model)\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:85\u001B[0m, in \u001B[0;36mmodel_from_config\u001B[1;34m(config, custom_objects)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# Replace keras refs with keras\u001B[39;00m\n\u001B[0;32m     83\u001B[0m config \u001B[38;5;241m=\u001B[39m _find_replace_nested_dict(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mserialization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODULE_OBJECTS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mALL_OBJECTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlayer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:495\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[0;32m    490\u001B[0m cls_config \u001B[38;5;241m=\u001B[39m _find_replace_nested_dict(\n\u001B[0;32m    491\u001B[0m     cls_config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    492\u001B[0m )\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustom_objects\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m arg_spec\u001B[38;5;241m.\u001B[39margs:\n\u001B[1;32m--> 495\u001B[0m     deserialized_obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcls_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mobject_registration\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGLOBAL_CUSTOM_OBJECTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    503\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m object_registration\u001B[38;5;241m.\u001B[39mCustomObjectScope(custom_objects):\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\models\\model.py:521\u001B[0m, in \u001B[0;36mModel.from_config\u001B[1;34m(cls, config, custom_objects)\u001B[0m\n\u001B[0;32m    516\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_functional_config \u001B[38;5;129;01mand\u001B[39;00m revivable_as_functional:\n\u001B[0;32m    517\u001B[0m     \u001B[38;5;66;03m# Revive Functional model\u001B[39;00m\n\u001B[0;32m    518\u001B[0m     \u001B[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001B[39;00m\n\u001B[0;32m    519\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functional_from_config\n\u001B[1;32m--> 521\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunctional_from_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[38;5;66;03m# Either the model has a custom __init__, or the config\u001B[39;00m\n\u001B[0;32m    526\u001B[0m \u001B[38;5;66;03m# does not contain all the information necessary to\u001B[39;00m\n\u001B[0;32m    527\u001B[0m \u001B[38;5;66;03m# revive a Functional model. This happens when the user creates\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    530\u001B[0m \u001B[38;5;66;03m# In this case, we fall back to provide all config into the\u001B[39;00m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;66;03m# constructor of the class.\u001B[39;00m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\models\\functional.py:477\u001B[0m, in \u001B[0;36mfunctional_from_config\u001B[1;34m(cls, config, custom_objects)\u001B[0m\n\u001B[0;32m    475\u001B[0m \u001B[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001B[39;00m\n\u001B[0;32m    476\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer_data \u001B[38;5;129;01min\u001B[39;00m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayers\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 477\u001B[0m     \u001B[43mprocess_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayer_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[38;5;66;03m# Then we process nodes in order of layer depth.\u001B[39;00m\n\u001B[0;32m    480\u001B[0m \u001B[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001B[39;00m\n\u001B[0;32m    481\u001B[0m \u001B[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001B[39;00m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;66;03m# is repeated until all nodes are processed.\u001B[39;00m\n\u001B[0;32m    483\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m unprocessed_nodes:\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\models\\functional.py:457\u001B[0m, in \u001B[0;36mfunctional_from_config.<locals>.process_layer\u001B[1;34m(layer_data)\u001B[0m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;66;03m# Instantiate layer.\u001B[39;00m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m layer_data:\n\u001B[0;32m    455\u001B[0m     \u001B[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001B[39;00m\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;66;03m# used for H5 and SavedModel formats\u001B[39;00m\n\u001B[1;32m--> 457\u001B[0m     layer \u001B[38;5;241m=\u001B[39m \u001B[43msaving_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_from_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    461\u001B[0m     layer \u001B[38;5;241m=\u001B[39m serialization_lib\u001B[38;5;241m.\u001B[39mdeserialize_keras_object(\n\u001B[0;32m    462\u001B[0m         layer_data, custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects\n\u001B[0;32m    463\u001B[0m     )\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:85\u001B[0m, in \u001B[0;36mmodel_from_config\u001B[1;34m(config, custom_objects)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# Replace keras refs with keras\u001B[39;00m\n\u001B[0;32m     83\u001B[0m config \u001B[38;5;241m=\u001B[39m _find_replace_nested_dict(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mserialization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODULE_OBJECTS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mALL_OBJECTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlayer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:504\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[0;32m    502\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    503\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m object_registration\u001B[38;5;241m.\u001B[39mCustomObjectScope(custom_objects):\n\u001B[1;32m--> 504\u001B[0m             deserialized_obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcls_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     \u001B[38;5;66;03m# Then `cls` may be a function returning a class.\u001B[39;00m\n\u001B[0;32m    507\u001B[0m     \u001B[38;5;66;03m# in this case by convention `config` holds\u001B[39;00m\n\u001B[0;32m    508\u001B[0m     \u001B[38;5;66;03m# the kwargs of the function.\u001B[39;00m\n\u001B[0;32m    509\u001B[0m     custom_objects \u001B[38;5;241m=\u001B[39m custom_objects \u001B[38;5;129;01mor\u001B[39;00m {}\n",
      "File \u001B[1;32mD:\\neuralnet_skeleton\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:236\u001B[0m, in \u001B[0;36mOperation.from_config\u001B[1;34m(cls, config)\u001B[0m\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig)\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError when deserializing class \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m using \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfig=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mException encountered: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    239\u001B[0m     )\n",
      "\u001B[1;31mTypeError\u001B[0m: Error when deserializing class 'DepthwiseConv2D' using config={'name': 'conv_dw_1', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}"
     ]
    }
   ],
   "source": [
    "model_rap = tf.keras.models.load_model('classificator_newgen_augment_gpu.h5', compile = False)\n",
    "model_rap.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model_rap.fit(X_train, y_train, epochs=5, validation_data=(X_val, y_val), batch_size = 32)\n",
    "model_rap.save('classificator_6_augmented_hsv.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T16:29:28.017828Z",
     "start_time": "2024-07-03T16:29:24.668189Z"
    }
   },
   "execution_count": 6
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
