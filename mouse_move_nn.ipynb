{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:43:06.930954600Z",
     "start_time": "2024-06-27T02:42:55.404721900Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_input():\n",
    "    X = []\n",
    "    y = []\n",
    "    df = pd.read_csv(\"classification_data/explore_img/explore_data.csv\")\n",
    "    shuffled_df = df.sample(len(df))\n",
    "\n",
    "    print(shuffled_df.head)\n",
    "    s = 0\n",
    "    for entry in shuffled_df.values:\n",
    "        s += 1\n",
    "        # print(s)\n",
    "        entry_img = cv2.imread(f\"classification_data/explore_img/{entry[0]}\")\n",
    "\n",
    "        prepared_y = np.delete(entry,0)\n",
    "\n",
    "        X.append(entry_img)\n",
    "        y.append(prepared_y)\n",
    "\n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).astype(np.float32)\n",
    "    return X, y\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:43:12.946836400Z",
     "start_time": "2024-06-27T02:43:12.919905300Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compile_model():\n",
    "    image_width, image_height, channels = 640, 360, 3  # Assuming RGB images\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(image_height, image_width, channels)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "\n",
    "    return model\n",
    "\n",
    "model = compile_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:43:17.697860500Z",
     "start_time": "2024-06-27T02:43:17.077246800Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:43:19.928020300Z",
     "start_time": "2024-06-27T02:43:19.904085800Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of           filename    x    y\n",
      "35  explore_35.jpg  467   61\n",
      "31  explore_31.jpg  291   50\n",
      "7    explore_7.jpg  322  311\n",
      "21  explore_21.jpg   40   65\n",
      "13  explore_13.jpg  328   23\n",
      "..             ...  ...  ...\n",
      "43  explore_43.jpg  432   56\n",
      "1    explore_1.jpg  437   50\n",
      "59  explore_59.jpg  475   52\n",
      "16  explore_16.jpg  114  159\n",
      "52  explore_52.jpg  391  302\n",
      "\n",
      "[64 rows x 3 columns]>\n",
      "(51, 360, 640, 3) (51, 2)\n"
     ]
    }
   ],
   "source": [
    "X, y = create_input()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:43:23.418187100Z",
     "start_time": "2024-06-27T02:43:22.923495400Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 1s/step - accuracy: 0.1097 - loss: 4227332.5000 - val_accuracy: 0.0769 - val_loss: 4096497.2500\n",
      "Epoch 2/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.1201 - loss: 3536922.7500 - val_accuracy: 0.0769 - val_loss: 856650.0625\n",
      "Epoch 3/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 974ms/step - accuracy: 0.1305 - loss: 667198.4375 - val_accuracy: 0.9231 - val_loss: 152762.3750\n",
      "Epoch 4/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 978ms/step - accuracy: 0.8799 - loss: 102339.1172 - val_accuracy: 0.9231 - val_loss: 18015.4590\n",
      "Epoch 5/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 977ms/step - accuracy: 0.8799 - loss: 23504.1387 - val_accuracy: 0.9231 - val_loss: 45432.3750\n",
      "Epoch 6/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 941ms/step - accuracy: 0.8930 - loss: 58219.1016 - val_accuracy: 0.9231 - val_loss: 21066.9473\n",
      "Epoch 7/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 952ms/step - accuracy: 0.9112 - loss: 21519.2559 - val_accuracy: 0.6923 - val_loss: 48302.1406\n",
      "Epoch 8/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.6893 - loss: 35650.3242 - val_accuracy: 0.9231 - val_loss: 68355.6094\n",
      "Epoch 9/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8903 - loss: 40680.8008 - val_accuracy: 0.9231 - val_loss: 41042.4727\n",
      "Epoch 10/10\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8564 - loss: 23542.3711 - val_accuracy: 0.9231 - val_loss: 13184.6035\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x21b534673e0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:43:58.471203400Z",
     "start_time": "2024-06-27T02:43:32.720508900Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - accuracy: 0.9231 - loss: 13184.6035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9230769276618958\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy:', accuracy)\n",
    "\n",
    "model.save('mouse_explore.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:44:05.944949200Z",
     "start_time": "2024-06-27T02:44:03.443081400Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332 72\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step\n",
      "365 161 \n",
      " 332 72\n",
      "487 42\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "371 97 \n",
      " 487 42\n",
      "467 61\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "352 98 \n",
      " 467 61\n",
      "476 290\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step\n",
      "335 89 \n",
      " 476 290\n",
      "550 249\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "368 118 \n",
      " 550 249\n"
     ]
    }
   ],
   "source": [
    "model_rap = tf.keras.models.load_model('mouse_explore_2.h5')\n",
    "\n",
    "\n",
    "for n in range(5):\n",
    "    x_real, y_real = int(y_val[n][0]), int(y_val[n][1])\n",
    "    print(x_real, y_real)\n",
    "    img = np.asarray(X_val[n])\n",
    "    \n",
    "    tbp = np.expand_dims(img, axis=0)\n",
    "    predictions = model_rap.predict(tbp)\n",
    "    x, y = int(predictions[0][0]), int(predictions[0][1]),\n",
    "    print(x, y, \"\\n\",x_real, y_real)\n",
    "    cv2.circle(img, (x,y), 10, (0,0,255), -1)\n",
    "    cv2.circle(img, (x_real, y_real), 10, (255,0,0), -1)\n",
    "    cv2.imshow('ss', img)\n",
    "    cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyWindow('ss')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:53:15.169991100Z",
     "start_time": "2024-06-27T02:52:36.786100100Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1s/step - accuracy: 0.7073 - loss: 348292.5625 - val_accuracy: 0.9231 - val_loss: 1103485.5000\n",
      "Epoch 2/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1s/step - accuracy: 0.8903 - loss: 800727.3750 - val_accuracy: 0.3846 - val_loss: 30010.0957\n",
      "Epoch 3/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.4359 - loss: 80281.7266 - val_accuracy: 0.0769 - val_loss: 206005.1875\n",
      "Epoch 4/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.1097 - loss: 220688.2656 - val_accuracy: 0.9231 - val_loss: 77908.8516\n",
      "Epoch 5/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8930 - loss: 87006.6484 - val_accuracy: 0.9231 - val_loss: 23671.4238\n",
      "Epoch 6/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 990ms/step - accuracy: 0.8903 - loss: 26873.2695 - val_accuracy: 0.9231 - val_loss: 16648.3047\n",
      "Epoch 7/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8695 - loss: 15295.3320 - val_accuracy: 0.9231 - val_loss: 17434.6543\n",
      "Epoch 8/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8695 - loss: 12352.1514 - val_accuracy: 0.9231 - val_loss: 22254.4375\n",
      "Epoch 9/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8695 - loss: 15624.5293 - val_accuracy: 0.9231 - val_loss: 25035.9902\n",
      "Epoch 10/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8695 - loss: 16912.3027 - val_accuracy: 0.9231 - val_loss: 23430.8105\n",
      "Epoch 11/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9007 - loss: 15040.6113 - val_accuracy: 0.9231 - val_loss: 18878.9238\n",
      "Epoch 12/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 986ms/step - accuracy: 0.8903 - loss: 12347.8389 - val_accuracy: 0.9231 - val_loss: 17249.4824\n",
      "Epoch 13/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 992ms/step - accuracy: 0.8695 - loss: 11751.8271 - val_accuracy: 0.9231 - val_loss: 17348.4043\n",
      "Epoch 14/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8903 - loss: 10862.0938 - val_accuracy: 0.9231 - val_loss: 16636.5137\n",
      "Epoch 15/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8695 - loss: 11053.9883 - val_accuracy: 0.9231 - val_loss: 15620.4111\n",
      "Epoch 16/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 976ms/step - accuracy: 0.8591 - loss: 10720.1143 - val_accuracy: 0.9231 - val_loss: 15725.6973\n",
      "Epoch 17/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 989ms/step - accuracy: 0.8903 - loss: 9800.7080 - val_accuracy: 0.9231 - val_loss: 16403.6289\n",
      "Epoch 18/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8799 - loss: 9121.5391 - val_accuracy: 0.9231 - val_loss: 16258.3213\n",
      "Epoch 19/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8903 - loss: 8778.5713 - val_accuracy: 0.9231 - val_loss: 15663.0146\n",
      "Epoch 20/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1s/step - accuracy: 0.8799 - loss: 6973.8599 - val_accuracy: 0.9231 - val_loss: 15147.9980\n",
      "Epoch 21/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.8695 - loss: 7057.4614 - val_accuracy: 0.9231 - val_loss: 14706.8135\n",
      "Epoch 22/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1s/step - accuracy: 0.9034 - loss: 5905.1943 - val_accuracy: 0.9231 - val_loss: 14400.9336\n",
      "Epoch 23/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1s/step - accuracy: 0.9373 - loss: 5251.3013 - val_accuracy: 0.9231 - val_loss: 14204.9785\n",
      "Epoch 24/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9165 - loss: 4954.5005 - val_accuracy: 0.9231 - val_loss: 14355.8242\n",
      "Epoch 25/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9165 - loss: 3901.5249 - val_accuracy: 0.9231 - val_loss: 14449.2744\n",
      "Epoch 26/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9295 - loss: 3799.4170 - val_accuracy: 0.9231 - val_loss: 14026.2051\n",
      "Epoch 27/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 982ms/step - accuracy: 0.9295 - loss: 3233.1963 - val_accuracy: 0.9231 - val_loss: 13596.0117\n",
      "Epoch 28/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9400 - loss: 2401.0505 - val_accuracy: 0.9231 - val_loss: 13395.3291\n",
      "Epoch 29/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9400 - loss: 2352.0000 - val_accuracy: 0.9231 - val_loss: 13209.2402\n",
      "Epoch 30/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9608 - loss: 1809.9299 - val_accuracy: 0.9231 - val_loss: 13226.0508\n",
      "Epoch 31/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9400 - loss: 1369.2550 - val_accuracy: 0.9231 - val_loss: 13439.8291\n",
      "Epoch 32/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9504 - loss: 1281.4728 - val_accuracy: 0.9231 - val_loss: 13494.8271\n",
      "Epoch 33/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9295 - loss: 1051.9299 - val_accuracy: 0.9231 - val_loss: 13115.5039\n",
      "Epoch 34/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1s/step - accuracy: 0.9869 - loss: 806.3245 - val_accuracy: 0.9231 - val_loss: 12909.5117\n",
      "Epoch 35/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9765 - loss: 715.7031 - val_accuracy: 0.9231 - val_loss: 12993.6523\n",
      "Epoch 36/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9608 - loss: 430.0396 - val_accuracy: 0.9231 - val_loss: 13108.0293\n",
      "Epoch 37/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 979ms/step - accuracy: 0.9400 - loss: 407.4570 - val_accuracy: 0.9231 - val_loss: 12705.4844\n",
      "Epoch 38/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1s/step - accuracy: 0.9869 - loss: 294.9870 - val_accuracy: 0.9231 - val_loss: 12438.5293\n",
      "Epoch 39/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1s/step - accuracy: 0.9739 - loss: 257.0397 - val_accuracy: 0.9231 - val_loss: 12548.4131\n",
      "Epoch 40/40\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 988ms/step - accuracy: 0.9165 - loss: 311.6686 - val_accuracy: 0.9231 - val_loss: 12671.2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_rap = tf.keras.models.load_model('mouse_explore.h5')\n",
    "model_rap.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_rap.fit(X_train, y_train, epochs=40, validation_data=(X_val, y_val))\n",
    "model_rap.save('mouse_explore_2.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T02:47:28.015414200Z",
     "start_time": "2024-06-27T02:45:52.041946800Z"
    }
   },
   "execution_count": 10
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
